{
  "brand_name": "Your Name",
  "brand_title": "システム・AI研究者",

  "nav_home": "ホーム",
  "nav_resume": "履歴書",
  "nav_portfolio": "ポートフォリオ",
  "nav_contact": "連絡",

  "profile_name": "Your Name",
  "profile_title": "On-device AI / GPU バーチャライゼーション",
  "profile_summary": "ハードウェアに最適化されたMLを設計し、実運用レベルでスケールさせるシステムを構築します。",

  "sidebar_profile_heading": "個人プロフィール",
  "sidebar_profile_body": "システム設計、ストーリー、プロトタイプで複雑な研究を実行可能な成果に変えます。",
  "sidebar_contact_heading": "コンタクト",
  "sidebar_contact_email_label": "メール",
  "sidebar_contact_email_value": "hello@example.com",
  "sidebar_contact_phone_label": "電話",
  "sidebar_contact_phone_value": "+82-10-7182-9744",
  "sidebar_contact_location_label": "場所",
  "sidebar_contact_location_value": "ソウル",
  "sidebar_contact_site_label": "サイト",
  "sidebar_contact_site_value": "junon-lee.pages.dev",
  "sidebar_education_heading": "学歴",
  "sidebar_education_one": "University of Seoul · M.S. Electrical and Computer Engineering",
  "sidebar_education_one_sub": "2025 - 現在",
  "sidebar_education_two": "University of Seoul · B.S. Electrical and Computer Engineering",
  "sidebar_education_two_sub": "2019 - 2025",
  "sidebar_skills_heading": "スキル",
  "sidebar_skill_one": "オンデバイスAI",
  "sidebar_skill_two": "GPUバーチャライゼーション",
  "sidebar_skill_three": "Mixture-of-Experts",
  "sidebar_skill_four": "プロファイリング",
  "sidebar_skill_five": "技術ドキュメント",
  "sidebar_projects_heading": "プロジェクト",
  "sidebar_project_one": "Edge Profiler",
  "sidebar_project_one_sub": "スケジューリング・テレメトリ",
  "sidebar_project_two": "KV Cache Compressor",
  "sidebar_project_two_sub": "レイテンシー圧縮",

  "intro_heading": "スペックシート概要",
  "intro_body": "このページから各カードでプロジェクトや論文の詳細ページへ移動できます。",
  "intro_cta_resume": "履歴書を見る",
  "intro_cta_portfolio": "ポートフォリオを見る",
  "intro_cta_contact": "連絡を送る",

  "home_featured": "注目の作品",
  "home_intro_desc": "エンジニアリング成果と研究をフィルタして、各詳細ページをご覧ください。",
  "filter_all": "全て",
  "filter_projects": "プロジェクト",
  "filter_research": "研究",

  "work_esmoe_title": "ES-MoE 推論最適化",
  "work_esmoe_sub": "スパースエキスパートルーティング",
  "work_esmoe_date": "2025.05",
  "work_orion_title": "Project Orion エッジスタック",
  "work_orion_sub": "テレメトリ＋復旧パイプライン",
  "work_orion_date": "2025.03",
  "work_llm_title": "効率的なLLMオフローディング",
  "work_llm_sub": "ジャーナルスタイルの発見",
  "work_llm_date": "2024.11",
  "work_cxl_title": "CXL対応のティアドメモリ",
  "work_cxl_sub": "マルチティア配置ポリシー",
  "work_cxl_date": "2024.08",

  "portfolio_intro_title": "ポートフォリオの概要",
  "portfolio_intro_desc": "エンジニアリングと研究成果をダミーテキストでまとめています。",
  "portfolio_projects_title": "エンジニアリングプロジェクト",
  "portfolio_projects_desc": "各タイルがプロジェクトの詳細ページにリンクします。",
  "portfolio_research_title": "研究と論文",
  "portfolio_research_desc": "査読付き論文と実験ノートを収集しました。",

  "resume_intro_title": "履歴書のスナップショット",
  "resume_intro_desc": "実務経験、研究、受賞をまとめたページです。",
  "resume_experience_title": "経験",
  "resume_exp1_role": "大学院研究員 · ACAS Lab",
  "resume_exp1_period": "2025 - 現在",
  "resume_exp1_desc": "ハイブリッドGPU/PIMクラスタでの推論最適化とランタイム自動化を担当。",
  "resume_exp2_role": "システムエンジニアインターン · FlexGen",
  "resume_exp2_period": "2024年夏",
  "resume_exp2_desc": "KVキャッシュスケジューリングカーネルとベンチマーク自動化を実装。",
  "resume_exp3_role": "システムプログラミングTA",
  "resume_exp3_period": "2024",
  "resume_exp3_desc": "40名以上にVerilog、GPUシミュレーター、OS計測の演習を指導。",
  "resume_research_title": "研究ハイライト",
  "resume_pub1_title": "ES-MoE: エッジ専門推論",
  "resume_pub1_meta": "査読中 · 第一著者",
  "resume_pub2_title": "Memory-aware LLM offloading",
  "resume_pub2_meta": "MLSys 2024 · 共著",
  "resume_pub3_title": "CXL-aware Tiering Policies",
  "resume_pub3_meta": "HPCA 2023 · 共著",
  "resume_projects_title": "代表プロジェクト",
  "resume_proj1_title": "Project Orion テレメトリ",
  "resume_proj1_desc": "耐障害性のある同期とリアルタイム健康スコアリング。",
  "resume_proj2_title": "FlexBench プロファイリング",
  "resume_proj2_desc": "LLM構成要素のレイテンシ/電力測定ツール。",
  "resume_awards_title": "受賞 & 認知",
  "resume_award1_title": "KAIST 大統領奨学金",
  "resume_award1_desc": "上位1%研究者への全額奨学金",
  "resume_award2_title": "優秀TA賞",
  "resume_award2_desc": "System Programming · 2024春",

  "contact_intro_title": "お問い合わせ",
  "contact_intro_desc": "訪問、講演、共同研究すべて歓迎です。",
  "contact_card_lab_title": "ラボ訪問",
  "contact_card_lab_desc": "週次の研究デモや実習に参加できます。",
  "contact_card_talks_title": "講演",
  "contact_card_talks_desc": "オンデバイスAIやGPUメモリチューニングの話をします。",
  "contact_card_collab_title": "協業",
  "contact_card_collab_desc": "オフローディングツールやシステム構築で協業を歓迎します。",
  "contact_form_title": "クイックメッセージ",
  "contact_form_desc": "話したいトピックを記入してください。すぐに返信します。",
  "contact_form_name": "お名前",
  "contact_form_email": "メール",
  "contact_form_message": "ご相談内容",
  "contact_form_cta": "送信",

  "detail_label_role": "役割",
  "detail_label_timeline": "期間",
  "detail_label_stack": "技術",
  "detail_overview_heading": "概要",
  "detail_contribution_heading": "主な貢献",
  "detail_findings_heading": "研究結果",
  "detail_outcome_heading": "インパクト",
  "detail_btn_visit": "サイト",
  "detail_btn_deck": "資料",
  "detail_btn_paper": "論文",
  "detail_btn_slides": "スライド",

  "detail_esmoe_title": "ES-MoE 推論最適化",
  "detail_esmoe_subtitle": "エッジGPU向け専門スケーリング",
  "detail_esmoe_role": "リード研究者",
  "detail_esmoe_timeline": "2024 - 2025",
  "detail_esmoe_stack": "PyTorch, CUDA Graphs, Triton",
  "detail_esmoe_overview": "スパース専門ルーティングとモニタリングスタックで小型GPUでも低レイテンシを実現。",
  "detail_esmoe_point1": "レイテンシを意識した専門選択を40µsで実行。",
  "detail_esmoe_point2": "ストリーミングKVキャッシュ圧縮で2倍のスループット達成。",
  "detail_esmoe_point3": "ダッシュボードで専門別利用率を可視化。",
  "detail_esmoe_outcome": "デモロボットで38%のレイテンシ削減。",

  "detail_orion_title": "Project Orion エッジ",
  "detail_orion_subtitle": "自律ドローンのテレメトリ",
  "detail_orion_role": "システムエンジニア",
  "detail_orion_timeline": "2023 - 2024",
  "detail_orion_stack": "Rust, gRPC, Prometheus, Azure IoT",
  "detail_orion_overview": "不安定なネットワークでもGPUメトリクスとミッションデータを同期。",
  "detail_orion_point1": "15分の接続切断を耐えるバッファ。",
  "detail_orion_point2": "GPU熱スロットルを即時表示。",
  "detail_orion_point3": "ミッション再生ダッシュボード提供。",
  "detail_orion_outcome": "サポート件数45%減、12件のパイロットで自主運用。",

  "detail_llm_title": "効率的なLLMオフローディング",
  "detail_llm_subtitle": "モバイルGPUパイプライン",
  "detail_llm_role": "第一著者",
  "detail_llm_timeline": "2024",
  "detail_llm_stack": "CUDA, PyTorch, FlexGen, TensorRT",
  "detail_llm_overview": "メモリ予算を守りながら長いシーケンスを維持するハイブリッド実行を定義。",
  "detail_llm_point1": "プリフィル・デコードを重ねるモデルを導出。",
  "detail_llm_point2": "6GB VRAM内で精度を維持するキャッシュ排出。",
  "detail_llm_point3": "Jetson Orinで1.6倍スループット。",
  "detail_llm_outcome": "モバイルLLM展開ガイドとして活用。",

  "detail_cxl_title": "CXL対応ティアードメモリ",
  "detail_cxl_subtitle": "HBM + CXLクラスタ",
  "detail_cxl_role": "共著者",
  "detail_cxl_timeline": "2023",
  "detail_cxl_stack": "CXLシミュレータ, Python, NVProf",
  "detail_cxl_overview": "CXL拡張を備えた多段階システムでKVキャッシュ移動ポリシーを探る。",
  "detail_cxl_point1": "CXLプールへの転送時の遅延予測器。",
  "detail_cxl_point2": "キュー遅延に応答するコントローラ。",
  "detail_cxl_point3": "CXL+HBM混合で27%コスト削減。",
  "detail_cxl_outcome": "産業パートナーのロードマップに貢献。",

  "footer_text": "(C) 2025 Your Name. All Rights Reserved."
}
