{
  "brand_name": "JUNON LEE",
  "brand_title": "시스템 · AI 연구자",

  "nav_home": "홈",
  "nav_resume": "이력서",
  "nav_portfolio": "포트폴리오",
  "nav_contact": "연락처",

  "profile_name": "이준헌",
  "profile_title": "온디바이스 AI / GPU 가상화",
  "profile_summary": "작고 빠른 하드웨어에 맞춘 메모리·GPU 시스템을 설계하여 제품 수준의 ML을 구현합니다.",

  "sidebar_profile_heading": "개인 프로필",
  "sidebar_profile_body": "시스템 설계와 스토리텔링, 프로토타입 제작으로 복잡한 연구를 실행 가능한 결과로 바꿉니다.",
  "sidebar_contact_heading": "연락처",
  "sidebar_contact_email_label": "이메일",
  "sidebar_contact_email_value": "wnsgjs34@gmail.com",
  "sidebar_contact_phone_label": "전화",
  "sidebar_contact_phone_value": "+82-10-7182-9744",
  "sidebar_contact_location_label": "위치",
  "sidebar_contact_location_value": "서울",
  "sidebar_contact_site_label": "사이트",
  "sidebar_contact_site_value": "junon-lee.pages.dev",
  "sidebar_education_heading": "학력",
  "sidebar_education_one": "서울시립대학교 · 전자전기컴퓨터공학부 석사",
  "sidebar_education_one_sub": "2025 - 현재",
  "sidebar_education_two": "서울시립대학교 · 전자전기컴퓨터공학과 학사",
  "sidebar_education_two_sub": "2019 - 2025",
  "sidebar_skills_heading": "스킬",
  "sidebar_skill_one": "온디바이스 AI",
  "sidebar_skill_two": "GPU 가상화",
  "sidebar_skill_three": "Mixture-of-Experts",
  "sidebar_skill_four": "프로파일링",
  "sidebar_skill_five": "기술 문서",
  "sidebar_projects_heading": "프로젝트",
  "sidebar_project_one": "Edge Profiler",
  "sidebar_project_one_sub": "스케줄링 + 텔레메트리",
  "sidebar_project_two": "KV Cache Compressor",
  "sidebar_project_two_sub": "지연 기반 압축",

  "intro_heading": "스펙 시트 개요",
  "intro_body": "페이지 상단 크레딧을 따라가며 각 카드를 클릭하면 프로젝트/논문 상세를 볼 수 있습니다.",
  "intro_cta_resume": "이력서 보기",
  "intro_cta_portfolio": "포트폴리오 보기",
  "intro_cta_contact": "문의하기",

  "home_featured": "추천 작업",
  "home_intro_desc": "엔지니어링 결과와 연구를 필터로 구분하고 각 상세를 확인해보세요.",
  "filter_all": "전체",
  "filter_projects": "프로젝트",
  "filter_research": "연구",

  "work_esmoe_title": "ES-MoE 추론 최적화",
  "work_esmoe_sub": "희소 전문가 루팅 런타임",
  "work_esmoe_date": "2025.05",
  "work_orion_title": "Project Orion 엣지 스택",
  "work_orion_sub": "텔레메트리 + 복구 파이프라인",
  "work_orion_date": "2025.03",
  "work_llm_title": "효율적인 LLM 오프로딩",
  "work_llm_sub": "논문 스타일의 발견",
  "work_llm_date": "2024.11",
  "work_cxl_title": "CXL 기반 티어드 메모리",
  "work_cxl_sub": "다중 티어 배치 정책",
  "work_cxl_date": "2024.08",

  "portfolio_intro_title": "포트폴리오 개요",
  "portfolio_intro_desc": "공학 빌드와 연구를 더미 텍스트로 정리했습니다.",
  "portfolio_projects_title": "엔지니어링 프로젝트",
  "portfolio_projects_desc": "각 카드가 프로젝트 상세 페이지로 연결됩니다.",
  "portfolio_research_title": "연구 & 논문",
  "portfolio_research_desc": "피어 리뷰 논문과 실험 노트를 모아두었습니다.",

  "resume_intro_title": "이력서 스냅샷",
  "resume_intro_desc": "핸즈온 경험, 논문, 수상 기록을 정리했습니다.",
  "resume_experience_title": "경력",
  "resume_exp1_role": "컴퓨터 아키텍처 석사과정 연구원 · ACAS Lab",
  "resume_exp1_period": "2025 - 현재",
  "resume_exp1_desc": "하이브리드 GPU/PIM 클러스터를 위한 추론 최적화와 런타임 자동화를 구축합니다.",
  "resume_exp2_role": "컴퓨터 구조 및 시스템 연구실 인턴  · ACAS Lab",
  "resume_exp2_period": "2024 - 2025",
  "resume_exp2_desc": "KV 캐시 스케줄링 커널과 벤치마크 자동화 코드를 구현했습니다.(희망)",
  "resume_exp3_role": "시스템 프로그래밍, 전자전기컴퓨터설계실험2 TA",
  "resume_exp3_period": "2025 2학기",
  "resume_exp3_desc": "Verilog 실습을 진행 및 강의했습니다.",
  "resume_exp4_role": "대한민국 공군",
  "resume_exp4_period": "2019 8월 - 2021 5월",
  "resume_exp4_desc": "개같이 굴렀습니다.",
  "resume_research_title": "연구 하이라이트",
  "resume_pub1_title": "ES-MoE: 엣지 전문가 추론(아님)",
  "resume_pub1_meta": "리뷰 중 · 제1저자",
  "resume_pub2_title": "Memory-aware LLM offloading(아님)",
  "resume_pub2_meta": "MLSys 2024 · 공저자",
  "resume_pub3_title": "CXL-aware Tiering Policies(아님)",
  "resume_pub3_meta": "HPCA 2023 · 공저자",
  "resume_projects_title": "대표 빌드",
  "resume_proj1_title": "Project Orion 텔레메트리(아님)",
  "resume_proj1_desc": "내결함 실시간 동기화와 헬스 스코어 파이프라인.",
  "resume_proj2_title": "FlexBench 프로파일링(아님)",
  "resume_proj2_desc": "LLM 컴포넌트 지연/전력 측정 도구.",
  "resume_awards_title": "수상 & 인정",
  "resume_award1_title": "UOS 대통령 장학금(희망)",
  "resume_award1_desc": "상위 1% 연구자 대상 전액 장학",
  "resume_award2_title": "우수 조교상(희망)",
  "resume_award2_desc": "System Programming · 2024 봄",

  "contact_intro_title": "문의 안내",
  "contact_intro_desc": "방문, 강연, 공동 연구 모두 환영합니다.",
  "contact_card_lab_title": "랩 방문",
  "contact_card_lab_desc": "주간 연구 데모와 실습에 참여할 수 있습니다.",
  "contact_card_talks_title": "강연",
  "contact_card_talks_desc": "온디바이스 AI와 GPU 메모리 튜닝의 강연을 제공합니다.",
  "contact_card_collab_title": "협업",
  "contact_card_collab_desc": "오프로드 툴링과 시스템 프로그래밍 협업을 찾고 있습니다.",
  "contact_form_title": "간단한 메시지",
  "contact_form_desc": "어떤 주제로 연락하실지 적어주시면 빠르게 회신합니다.",
  "contact_form_name": "이름",
  "contact_form_email": "이메일",
  "contact_form_message": "프로젝트 내용",
  "contact_form_cta": "보내기",

  "detail_label_role": "역할",
  "detail_label_timeline": "기간",
  "detail_label_stack": "기술",
  "detail_overview_heading": "개요",
  "detail_contribution_heading": "핵심 기여",
  "detail_findings_heading": "연구 결과",
  "detail_outcome_heading": "임팩트",
  "detail_btn_visit": "사이트",
  "detail_btn_deck": "자료",
  "detail_btn_paper": "논문",
  "detail_btn_slides": "슬라이드",

  "detail_esmoe_title": "ES-MoE 추론 최적화",
  "detail_esmoe_subtitle": "엣지 GPU 전문가 스케일링",
  "detail_esmoe_role": "리드 연구자",
  "detail_esmoe_timeline": "2024 - 2025",
  "detail_esmoe_stack": "PyTorch, CUDA Graphs, Triton",
  "detail_esmoe_overview": "희소 전문가 라우팅과 관측 스택으로 저지연 추론을 유지합니다.",
  "detail_esmoe_point1": "40µs 내의 전문 선택 로직.",
  "detail_esmoe_point2": "스트리밍 KV 캐시 압축으로 2배 처리량.",
  "detail_esmoe_point3": "전문가별 사용률 대시보드.",
  "detail_esmoe_outcome": "데모 로봇에서 38% 지연 감소.",

  "detail_orion_title": "Project Orion 엣지",
  "detail_orion_subtitle": "자율 드론 텔레메트리",
  "detail_orion_role": "시스템 엔지니어",
  "detail_orion_timeline": "2023 - 2024",
  "detail_orion_stack": "Rust, gRPC, Prometheus, Azure IoT",
  "detail_orion_overview": "불안정한 네트워크에서도 GPU와 미션 데이터 동기화합니다.",
  "detail_orion_point1": "15분 통신 두절 방어 버퍼링.",
  "detail_orion_point2": "GPU 열 스로틀 즉시 노출.",
  "detail_orion_point3": "미션 재생 대시보드 제공.",
  "detail_orion_outcome": "지원 이슈 45% 감소, 12개 파일럿에서 무인 운영.",

  "detail_llm_title": "효율적인 LLM 오프로딩",
  "detail_llm_subtitle": "모바일 GPU 파이프라인",
  "detail_llm_role": "제1저자",
  "detail_llm_timeline": "2024",
  "detail_llm_stack": "CUDA, PyTorch, FlexGen, TensorRT",
  "detail_llm_overview": "메모리 예산을 지키면서 긴 시퀀스를 처리하는 하이브리ッド 실행.",
  "detail_llm_point1": "프리필·디코드 겹침 모델.",
  "detail_llm_point2": "6GB VRAM 내 캐시 축출 유지.",
  "detail_llm_point3": "Jetson Orin에서 1.6배 처리량.",
  "detail_llm_outcome": "모바일 LLM 배포 가이드로 활용.",

  "detail_cxl_title": "CXL 기반 티어드 메모리",
  "detail_cxl_subtitle": "HBM + CXL 클러스터",
  "detail_cxl_role": "공저자",
  "detail_cxl_timeline": "2023",
  "detail_cxl_stack": "CXL 시뮬레이터, Python, NVProf",
  "detail_cxl_overview": "CXL 확장기를 갖춘 다중 티어 시스템의 KV 캐시 정책을 탐색합니다.",
  "detail_cxl_point1": "텐서를 CXL로 옮길지 결정하는 지연 예측.",
  "detail_cxl_point2": "큐 지연 스파이크에 반응하는 컨트롤러.",
  "detail_cxl_point3": "CXL+HBM 혼합으로 27% 비용 절감.",
  "detail_cxl_outcome": "산업 파트너 로드맵에 반영.",

  "footer_text": "(C) 2025 Your Name. All Rights Reserved."
}
