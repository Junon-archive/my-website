window.TRANSLATION_DATA = {
  "en": {
    "brand_name": "JUNON LEE",
    "brand_title": "Systems & AI Researcher",
    "nav_home": "Home",
    "nav_resume": "Resume",
    "nav_portfolio": "Portfolio",
    "nav_contact": "Contact",
    "profile_name": "JUN-HEON LEE",
    "profile_title": " GPU Architecture / On-device AI",
    "profile_summary": "I engineer hardware-conscious ML systems that stay lean yet scale to production workloads.",
    "sidebar_profile_heading": "Personal profile",
    "sidebar_profile_body": "I am a researcher working on on-device AI and GPU memory systems. My work focuses on developing structural optimization techniques that enable large-scale models to run reliably even under limited hardware resources.",
    "sidebar_contact_heading": "Contact",
    "sidebar_contact_email_label": "Email",
    "sidebar_contact_email_value": "wnsgjs34@gmail.com",
    "sidebar_contact_phone_label": "Phone",
    "sidebar_contact_phone_value": "+82-10-7182-9744",
    "sidebar_contact_location_label": "Location",
    "sidebar_contact_location_value": "Seoul, South Korea",
    "sidebar_contact_site_label": "Website",
    "sidebar_contact_site_value": "junon-lee.pages.dev",
    "sidebar_education_heading": "Education",
    "sidebar_education_one": "University of Seoul · M.S. Electrical and Computer Engineering",
    "sidebar_education_one_sub": "2025 - Present",
    "sidebar_education_two": "University of Seoul · B.S. Electrical and Computer Engineering",
    "sidebar_education_two_sub": "2019 - 2025",
    "sidebar_skills_heading": "Skills",
    "sidebar_skill_one": "On-device AI",
    "sidebar_skill_two": "GPU virtualization",
    "sidebar_skill_three": "Mixture-of-experts",
    "sidebar_skill_four": "Profiling & tooling",
    "sidebar_skill_five": "Technical writing",
    "sidebar_projects_heading": "Highlighted projects",
    "sidebar_project_one": "Edge Profiler",
    "sidebar_project_one_sub": "Scheduling + telemetry stack",
    "sidebar_project_two": "KV Cache Compressor",
    "sidebar_project_two_sub": "Latency-aware compression",
    "intro_heading": "Spec sheet overview",
    "intro_body": "The portfolio is anchored by this page. Every block below links to a more detailed project or publication entry.",
    "intro_cta_resume": "Open resume",
    "intro_cta_portfolio": "View portfolio",
    "intro_cta_contact": "Drop a note",
    "home_featured": "Featured work",
    "home_intro_desc": "Filter between engineering deliverables and research write-ups, then click a card to explore the case study.",
    "filter_all": "All",
    "filter_projects": "Projects",
    "filter_research": "Research",
    "work_esmoe_title": "ES-MoE inference optimizer",
    "work_esmoe_sub": "Sparse expert routing runtime",
    "work_esmoe_date": "2025.05",
    "work_orion_title": "Project Orion edge stack",
    "work_orion_sub": "Telemetry + remediation pipeline",
    "work_orion_date": "2025.03",
    "work_llm_title": "Efficient LLM offloading",
    "work_llm_sub": "Journal-style findings",
    "work_llm_date": "2024.11",
    "work_cxl_title": "CXL-aware tiered memory",
    "work_cxl_sub": "Multi-tier placement policy",
    "work_cxl_date": "2024.08",
    "work_5g_title": "5G O-RAN network simulation",
    "work_5g_sub": "Core↔RIC↔gNB bring-up",
    "work_5g_date": "2025.06",
    "work_ebpf_title": "Practical Latency Observability with eBPF",
    "work_ebpf_sub": "CPU, memory, and I/O latency measurements",
    "work_ebpf_date": "In progress",
    "work_moh_title": "Memory-efficient LLM inference via MoH offloading",
    "work_moh_sub": "Head-wise routing traces and system trade-offs",
    "work_moh_date": "In progress",
    "work_pim_title": "PIM-accelerated gradient accumulation for 3DGS-SLAM",
    "work_pim_sub": "Atomic-conflict mitigation via bank-local reduction",
    "work_pim_date": "In progress",
    "portfolio_intro_title": "Portfolio overview",
    "portfolio_intro_desc": "This page showcases the research and projects I have worked on.",
    "portfolio_projects_title": "Engineering projects",
    "portfolio_projects_desc": "Each tile routes to a project detail page with research-worthy copy.",
    "portfolio_research_title": "Research & publications",
    "portfolio_research_desc": "Summaries of work and notes from recent experiments.",
    "resume_intro_title": "Resume snapshot",
    "resume_intro_desc": "This page lists the hands-on experience, publications, and awards that kept the home hero concise.",
    "resume_experience_title": "Experience",
    "resume_exp1_role": "Graduate researcher · ACAS Lab",
    "resume_exp1_period": "2025 - Present",
    "resume_exp1_desc": "Building inference optimizers and runtime automation for hybrid GPU/PIM clusters.",
    "resume_exp2_role": "Systems engineer intern · ACAS Lab",
    "resume_exp2_period": "Summer 2024",
    "resume_exp2_desc": "Implemented KV cache scheduling kernels and benchmark automation on Blackwell hardware.",
    "resume_exp3_role": "Teaching assistant · Systems programming",
    "resume_exp3_period": "2024",
    "resume_exp3_desc": "Led labs covering Verilog, GPU simulation, and OS instrumentation for 40+ students.",
    "resume_exp4_role": "Airforce, Republic of Korea",
    "resume_exp4_period": "Aug 2019 - May 2021",
    "resume_exp4_desc": "Staff sergeant/ honorable discharge",
    "resume_research_title": "Research highlights",
    "resume_pub1_title": "Research highlights 1",
    "resume_pub1_meta": "To be added",
    "resume_pub2_title": "Research highlights 2",
    "resume_pub2_meta": "To be added",
    "resume_pub3_title": "Research highlights 3",
    "resume_pub3_meta": "To be added",
    "resume_projects_title": "Selected builds",
    "resume_proj1_title": "Selected builds 1",
    "resume_proj1_desc": "To be added",
    "resume_proj2_title": "Selected builds 2",
    "resume_proj2_desc": "To be added",
    "resume_awards_title": "Awards & recognition",
    "resume_award1_title": "Next-Generation Communications Convergence Program (Winter Internship) | CAN Communication Project — Excellence Award",
    "resume_award1_desc": "Received an Excellence Award for a CAN communication project during the winter industry internship program. 2025.01",
    "resume_award2_title": "Incheon Student Policy Presentation Competition — Grand Prize",
    "resume_award2_desc": "Won the Grand Prize for a municipal policy pitch presentation, 2019.08",
    "contact_intro_title": "Contact guide",
    "contact_intro_desc": "Share a quick note or book a visit. Below are the doors that stay open.",
    "contact_card_lab_title": "Lab visits",
    "contact_card_lab_desc": "Room 613, IT Building, University of Seoul, Seoul",
    "contact_card_talks_title": "TA / Lab Sessions",
    "contact_card_talks_desc": "Please contact me via email or phone.",
    "contact_card_collab_title": "Collaboration",
    "contact_card_collab_desc": "Open to joint research in related fields.",
    "contact_card_career_title": "Recruiting",
    "contact_card_career_desc": "Open to R&D opportunities in AI systems, GPU architecture, and system optimization.",
    "contact_form_title": "Quick message",
    "contact_form_desc": "Drop the topic you want to chat about and I will reply soon.",
    "contact_form_name": "Your name",
    "contact_form_email": "Work email",
    "contact_form_message": "Reason for writing",
    "contact_form_cta": "Send message",
    "detail_label_role": "Role",
    "detail_label_timeline": "Timeline",
    "detail_label_stack": "Stack",
    "detail_overview_heading": "Overview",
    "detail_contribution_heading": "Key contributions",
    "detail_findings_heading": "Research findings",
    "detail_outcome_heading": "Impact",
    "detail_btn_visit": "Visit site",
    "detail_btn_deck": "Download deck",
    "detail_btn_paper": "Read paper",
    "detail_btn_slides": "View slides",
    "detail_esmoe_title": "ES-MoE inference optimizer",
    "detail_esmoe_subtitle": "Expert-scaling toolkit for edge GPUs",
    "detail_esmoe_role": "Lead researcher",
    "detail_esmoe_timeline": "2024 - 2025",
    "detail_esmoe_stack": "PyTorch, CUDA Graphs, Triton",
    "detail_esmoe_overview": "Optimized sparse MoE routing with latency-aware placement and instrumentation for small GPU pods.",
    "detail_esmoe_point1": "Designed a 40µs expert selection that respects device bandwidth.",
    "detail_esmoe_point2": "Implemented streaming KV cache compression with 2× throughput vs. PyTorch baseline.",
    "detail_esmoe_point3": "Delivered dashboards showing per-expert utilization across deployments.",
    "detail_esmoe_outcome": "Reduced end-to-end latency by 38% on ACAS Lab robots.",
    "detail_orion_title": "Project Orion edge stack",
    "detail_orion_subtitle": "Telemetry + resilience for autonomous drones",
    "detail_orion_role": "Systems engineer",
    "detail_orion_timeline": "2023 - 2024",
    "detail_orion_stack": "Rust, gRPC, Prometheus, Azure IoT",
    "detail_orion_overview": "Built reliable pipelines syncing GPU metrics and mission data even over flaky links.",
    "detail_orion_point1": "Shipped adaptive buffering surviving 15-minute disconnects.",
    "detail_orion_point2": "Exposed GPU thermal throttling through profiler hooks.",
    "detail_orion_point3": "Packaged mission replay dashboards for field teams.",
    "detail_orion_outcome": "Cut support escalations by 45% and enabled 12 pilot programs.",
    "detail_llm_title": "Efficient LLM offloading",
    "detail_llm_subtitle": "Pipeline scheduling for mobile GPUs",
    "detail_llm_role": "First author",
    "detail_llm_timeline": "2024",
    "detail_llm_stack": "CUDA, PyTorch, FlexGen, TensorRT",
    "detail_llm_overview": "Quantifies hybrid CPU/GPU execution that preserves large sequences inside memory budgets.",
    "detail_llm_point1": "Derived overlapping prefill/decode models under bandwidth limits.",
    "detail_llm_point2": "Introduced progressive cache eviction within 6 GB VRAM.",
    "detail_llm_point3": "Benchmarked on Jetson Orin with 1.6× throughput gains.",
    "detail_llm_outcome": "Spotlight talk; widely cited for mobile LLM deployments.",
    "detail_cxl_title": "CXL-aware tiered memory",
    "detail_cxl_subtitle": "Dynamic placement for HBM + CXL clusters",
    "detail_cxl_role": "Co-author",
    "detail_cxl_timeline": "2023",
    "detail_cxl_stack": "CXL simulator, Python, NVProf",
    "detail_cxl_overview": "Modeled multi-tier nodes with CXL expanders and explored cache migration heuristics.",
    "detail_cxl_point1": "Proposed latency predictors for spilling tensors to CXL pools.",
    "detail_cxl_point2": "Implemented a feedback controller reacting to queueing spikes.",
    "detail_cxl_point3": "Achieved 27% better cost-per-query by mixing CXL and HBM.",
    "detail_cxl_outcome": "Influenced hardware roadmaps with industry partners.",
    "detail_moh_title": "Memory-Efficient LLM Inference via MoH-Guided Head-wise Offloading (In Progress)",
    "detail_moh_subtitle": "Routing trace analysis -> head importance & regularity -> offloading/prefetch strategies -> accuracy/performance trade-off validation",
    "detail_moh_overview": "Large Language Model (LLM) inference is often bottlenecked by attention-related memory costs (KV cache footprint, memory movement, and host-device transfers). This project tests whether Mixture-of-Head Attention routing signals can reduce effective attention cost by using fewer heads or handling heads differently while preserving output quality.",
    "detail_moh_point1": "Built a router-trace pipeline that records token-level head selection/scores and generates analysis artifacts (plots/tables).",
    "detail_moh_point2": "Quantified accuracy vs rho trade-offs and tested head-regularity hypotheses with Jaccard similarity and layer/token comparisons.",
    "detail_moh_point3": "Derived offloading strategies (naive offload, keep-hot, prefetch/overlap) and packaged reproducible scripts, configs, and summary tables.",
    "detail_moh_arch_heading": "System Architecture",
    "detail_moh_arch_body": "Target model: MoH-based LLM (e.g., MoH-LLaMA3-8B) with router outputs logged per token. Inference stack uses PyTorch/Transformers with custom routing hooks; traces (npz) feed analysis scripts and reporting tables. Hardware uses a GPU (e.g., NVIDIA L40) plus host CPU/RAM with PCIe transfers where pinned memory and async overlap matter.",
    "detail_moh_pipeline_heading": "Bring-up Pipeline",
    "detail_moh_pipeline_step1": "Collect router traces by running inference with controlled prompts/workloads (scripts/run_router_trace.py) and logging token-level routing traces to traces/....",
    "detail_moh_pipeline_step2": "Visualize trace statistics (head activation frequency, Jaccard similarity, layer/token regularity) to validate reuse signals.",
    "detail_moh_pipeline_step3": "Run rho (or Top-K) sweeps to measure accuracy degradation and extend to latency/throughput and system metrics (PCIe bytes, overlap ratio).",
    "detail_moh_pipeline_step4": "Evaluate offloading strategies (naive, keep-hot with window tau, prefetch/overlap) and document required priors plus gains/losses.",
    "detail_moh_validation_heading": "Validation & Evidence",
    "detail_moh_validation_item1": "Accuracy vs rho shows a clear trade-off, with limited loss in a gentle regime before a sharper drop beyond a threshold.",
    "detail_moh_validation_item2": "Regularity is limited; simple reuse heuristics can be misleading without robust statistical validation.",
    "detail_moh_validation_item3": "Next: add system metrics (latency/throughput, GPU memory peak, PCIe bytes, overlap ratio) to explain wins or failures.",
    "detail_moh_debug_heading": "Debugging Case Study",
    "detail_moh_debug_symptom_label": "Symptom",
    "detail_moh_debug_symptom": "Reducing heads or introducing offloading sometimes yields small gains or even slowdowns.",
    "detail_moh_debug_hypothesis_label": "Hypotheses",
    "detail_moh_debug_hypothesis": "H1: many small transfers dominate latency; H2: lack of pinned memory/async copy prevents overlap; H3: router tracing/logging overhead contaminates timing.",
    "detail_moh_debug_tests_label": "Tests",
    "detail_moh_debug_tests": "Microbenchmarks for H2D/D2H bandwidth vs transfer size and copy+compute overlap; ablations toggling logging, batching transfers, and isolating trace collection.",
    "detail_moh_debug_fix_label": "Fix",
    "detail_moh_debug_fix": "Use pinned memory and async transfers, adjust transfer granularity (batching), apply keep-hot with window tau, and isolate trace collection from performance measurements.",
    "detail_moh_debug_takeaway_label": "Takeaway",
    "detail_moh_debug_takeaway": "Algorithmic sparsity alone is insufficient; transfer granularity, overlap, and implementation details decide system-level performance.",
    "detail_moh_skills_heading": "Skills Demonstrated",
    "detail_moh_skills_item1": "LLM inference profiling and experimental design (accuracy-latency trade-offs).",
    "detail_moh_skills_item2": "Token/head trace analytics (similarity, repetition, distribution).",
    "detail_moh_skills_item3": "Systems thinking for host-device movement (PCIe, pinned memory, overlap).",
    "detail_moh_skills_item4": "Reproducible research workflow (scripts, configs, plots, reporting tables).",
    "detail_moh_artifacts_heading": "Artifacts",
    "detail_moh_artifact_traces": "Router traces & analytics (traces/, analysis/, tables/)",
    "detail_moh_artifact_scripts": "Execution scripts & reproducible commands (scripts/run_router_trace.py)",
    "detail_pim_title": "PIM-Accelerated Gradient Accumulation for 3DGS-SLAM (In Progress)",
    "detail_pim_subtitle": "Atomic-conflict mitigation via bank-local reductions",
    "detail_pim_overview": "3D Gaussian Splatting SLAM pipelines spend most time in tracking/mapping where Rendering BP dominates. Gradient accumulation becomes highly contended atomic adds, so this work reframes the problem: eliminate global atomics via host-side bank binning and bank-local PIM reduction.",
    "detail_pim_point1": "Bottleneck characterization plus PIM-friendly reformulation from global atomicAdd to bank-local reduction using host binning.",
    "detail_pim_point2": "Fair baselines with GPU atomicAdd, GPU block-reduction, and proposed PIM bank-local reduction under controlled contention sweeps.",
    "detail_pim_point3": "Measurement-first pipeline with latency/cycle, atomic pressure, and data-movement metrics and reproducible plots.",
    "detail_pim_arch_heading": "System Architecture",
    "detail_pim_arch_body": "Input is P fragments with gaussian_id and grad[D], output is acc[G][D]. GPU baseline uses atomicAdd to acc[gaussian_id], which serializes under contention. PIM path bins fragments by bank (gaussian_id % num_banks), performs bank-local accumulation in PIM, then writes back only as needed.",
    "detail_pim_pipeline_heading": "Bring-up Pipeline",
    "detail_pim_pipeline_step1": "Abstract Rendering BP into a standalone gradient-accumulation workload with synthetic or trace-driven inputs.",
    "detail_pim_pipeline_step2": "Build GPU baselines: global atomicAdd and block-level reduction to reduce atomics.",
    "detail_pim_pipeline_step3": "Implement PIM bank-local reduction in SAIT PIMSimulator with host-side binning and clean host vs PIM responsibilities.",
    "detail_pim_pipeline_step4": "Run parameter sweeps (P, G, D, distribution skew) and generate speedup/scale/step-breakdown plots.",
    "detail_pim_validation_heading": "Validation & Evidence",
    "detail_pim_validation_item1": "Correctness by comparing GPU vs PIM accumulators (max_abs_error, L2 or relative error) under fixed seeds.",
    "detail_pim_validation_item2": "Performance metrics: GPU kernel latency and atomic pressure; PIM cycles plus host-memory data movement.",
    "detail_pim_validation_item3": "Evidence target: as contention rises (Zipf skew), GPU-atomic degrades sharply while PIM bank-local stays stable or degrades slower.",
    "detail_pim_debug_heading": "Debugging Case Study",
    "detail_pim_debug_symptom_label": "Symptom",
    "detail_pim_debug_symptom": "PIM results were sometimes incorrect or showed suspicious speedups that did not match expected compute or memory behavior.",
    "detail_pim_debug_hypothesis_label": "Hypotheses",
    "detail_pim_debug_hypothesis": "Host performed work intended for PIM, payload encoding mismatched, or binning layout/boundaries broke bank-locality assumptions.",
    "detail_pim_debug_tests_label": "Tests",
    "detail_pim_debug_tests": "Lock inputs and compare GPU-Atomic, GPU-BlockReduce, and PIM-Reduce while timing stages for binning, accumulate, and write-back.",
    "detail_pim_debug_fix_label": "Fix",
    "detail_pim_debug_fix": "Define responsibilities strictly (host binning only, PIM address generation and accumulation), make binning layouts explicit, and report per-stage latency.",
    "detail_pim_debug_takeaway_label": "Takeaway",
    "detail_pim_debug_takeaway": "Fair PIM comparisons require transparent staging costs and unambiguous data layout definitions.",
    "detail_pim_skills_heading": "Skills Demonstrated",
    "detail_pim_skills_item1": "Contention-focused bottleneck analysis beyond FLOP counts.",
    "detail_pim_skills_item2": "Workload reformulation for bank-local, memory-centric execution models.",
    "detail_pim_skills_item3": "Controlled experimental design with strong GPU baselines and skewed distributions.",
    "detail_pim_skills_item4": "Simulator-oriented implementation and reproducible measurement pipelines.",
    "detail_pim_artifacts_heading": "Artifacts",
    "detail_pim_artifact_plan": "Problem definition + experiment plan (PIM vs GPU for Rendering BP accumulation)",
    "detail_pim_artifact_impl": "Baseline kernels + SAIT PIMSimulator integration (bank-local reduction path)",
    "detail_ebpf_title": "Practical Latency Observability with eBPF",
    "detail_ebpf_subtitle": "Measuring CPU, Memory, and I/O Bottlenecks in Linux Kernel",
    "detail_ebpf_overview": "Modern systems suffer from performance bottlenecks that are often invisible at user space. CPU scheduling delays, memory access latency, and block I/O stalls frequently dominate end-to-end performance, yet they are difficult to measure precisely without kernel-level instrumentation. This project implements a practical eBPF-based latency observability toolkit that measures these three bottleneck sources with a unified interface, consistent UX, and reproducible workflows.",
    "detail_ebpf_point1": "Unified UX with shared CLI flags (--duration, --out) and histogram-based outputs across CPU, memory, and I/O tools.",
    "detail_ebpf_point2": "Reproducibility via fixed-duration measurements, a one-click collection script, and environment metadata stored alongside results.",
    "detail_ebpf_point3": "Interpretability using log2 latency buckets, tail-latency focus, and CSV + JSON summaries for comparison.",
    "detail_ebpf_arch_heading": "System Architecture",
    "detail_ebpf_arch_body": "The toolkit consists of three independent eBPF programs (memlat, runqlat, iolat) and a shared user-space control layer. Kernel tracepoints are attached using eBPF, entry/exit timestamps are recorded in BPF maps, latency deltas are computed in-kernel, results are aggregated into histograms, and user-space programs collect and serialize the data without modifying application code.",
    "detail_ebpf_pipeline_heading": "Measurement Workflow",
    "detail_ebpf_pipeline_step1": "Attach kernel tracepoints with eBPF, record entry/exit timestamps in BPF maps, and compute latency deltas in kernel space.",
    "detail_ebpf_pipeline_step2": "Aggregate results into log2 histograms, then collect and serialize in user space.",
    "detail_ebpf_pipeline_step3": "Run the unified collection script (scripts/collect_all.sh --duration 30s --out results/week2_one_click) to execute all three tools sequentially.",
    "detail_ebpf_pipeline_step4": "Store outputs as memlat.csv/runqlat.csv/iolat.csv plus matching .summary.json files for comparison.",
    "detail_ebpf_validation_heading": "Validation & Evidence",
    "detail_ebpf_validation_item1": "CPU scheduling latency exhibits a long tail under load, even when utilization appears normal.",
    "detail_ebpf_validation_item2": "Memory latency stays stable unless page faults are induced, then tail buckets spike.",
    "detail_ebpf_validation_item3": "I/O latency clusters by request size and device behavior, confirming tail-dominated slowdowns.",
    "detail_ebpf_debug_heading": "Debugging Case Study",
    "detail_ebpf_debug_symptom_label": "Symptom",
    "detail_ebpf_debug_symptom": "Performance analysis still felt unreliable when measurements were inconsistent or hard to compare across runs.",
    "detail_ebpf_debug_hypothesis_label": "Hypotheses",
    "detail_ebpf_debug_hypothesis": "Inconsistent measurement methods and missing context made tail behavior difficult to interpret.",
    "detail_ebpf_debug_tests_label": "Tests",
    "detail_ebpf_debug_tests": "Standardized duration and output format across tools, then reran identical workloads to check stability and variability.",
    "detail_ebpf_debug_fix_label": "Fix",
    "detail_ebpf_debug_fix": "Enforced a unified CLI, fixed-duration collection, and metadata capture to make runs comparable.",
    "detail_ebpf_debug_takeaway_label": "Takeaway",
    "detail_ebpf_debug_takeaway": "Consistent, reproducible measurement beats ad-hoc tracing for real-world debugging.",
    "detail_ebpf_skills_heading": "Skills Demonstrated",
    "detail_ebpf_skills_item1": "Kernel-level observability with eBPF and CO-RE/BTF aware tooling.",
    "detail_ebpf_skills_item2": "Latency analysis for CPU scheduling, memory access, and block I/O bottlenecks.",
    "detail_ebpf_skills_item3": "Reproducible experiment design with one-click collection and metadata capture.",
    "detail_ebpf_skills_item4": "User-space tooling in Go and consistent CLI/data formats.",
    "detail_ebpf_artifacts_heading": "Artifacts",
    "detail_ebpf_artifact_toolkit": "Unified eBPF toolkit (memlat/runqlat/iolat) with shared CLI",
    "detail_ebpf_artifact_results": "Experiment outputs: CSV histograms + JSON summaries",
    "detail_5g_title": "5G O-RAN end-to-end simulation",
    "detail_5g_subtitle": "Bringing Open5GS, srsRAN, and O-RAN SC together",
    "detail_5g_role": "Systems engineer",
    "detail_5g_timeline": "2025",
    "detail_5g_stack": "Open5GS, srsRAN, O-RAN SC RIC",
    "detail_5g_overview": "Recreated an end-to-end 5G stack connecting Open5GS (Core), srsRAN gNB/UE, and the O-RAN SC RIC over E2, while preserving every bring-up artifact (configs, Docker networking, namespaces) so the lab report is reproducible.",
    "detail_5g_point1": "Scripted the srsRAN combo (`docker compose up 5gc`, `./gnb -c gnb_zmq.yaml`, `./srsue ue_zmq.conf`) with explicit namespaces, ports, and NAT tweaks to prove attachment from Core to UE.",
    "detail_5g_point2": "Started the O-RAN SC RIC and tied it to the gNB to validate the E2 control-plane handshake as soon as both containers were available.",
    "detail_5g_point3": "Tracked gNB startup failures by auditing AMF reachability, YAML/PCAP settings, and permissions; when the INI parser stalled, we refreshed the build and rerouted to a known-good workflow.",
    "detail_5g_outcome": "Captured the commands, configs, and debugging notes so future teams can reproduce the Core→RIC→UE cycle without hunting for missing files.",
    "detail_5g_arch_heading": "System Architecture",
    "detail_5g_arch_body": "UE (srsRAN) ↔ gNB (srsRAN) ↔ Open5GS Core with the O-RAN SC RIC attached via 5G RAN E2 interfaces; every service runs in Docker Compose, networks isolated with namespaces, NAT rules, and service labels.",
    "detail_5g_pipeline_heading": "Bring-up Pipeline",
    "detail_5g_pipeline_step1": "Start Open5GS 5gc container (`docker compose up 5gc`), confirm AMF/SMF/NSSF services and northbound gNodeB/IP reachability.",
    "detail_5g_pipeline_step2": "Bring up the O-RAN SC RIC so E2AP stacks can register gobally; inspect `ric` logs for heartbeat then set RAN node config to open E2 connections.",
    "detail_5g_pipeline_step3": "Launch srsRAN gNB with E2 enabled (`./gnb -c gnb_zmq.yaml e2`) in the same namespace, verifying gNB local interfaces plus correct PCAP path/version.",
    "detail_5g_pipeline_step4": "Activate srsRAN UE (`./srsue ue_zmq.conf`), observe NAS attach, then run `ping`/`traceroute` through the namespace to prove UE ↔ Core connectivity.",
    "detail_5g_validation_heading": "Validation & Evidence",
    "detail_5g_validation_item1": "Open5GS health check shows AMF/NSSF threads bound to 38412 and publishes service stats before gNB startup.",
    "detail_5g_validation_item2": "RIC reports E2 session establishment when the gNB registers, so the control plane handshake was verified via the REST debug API.",
    "detail_5g_validation_item3": "UE attaches and receives IP; `ping`/`iperf` from the UE namespace to the core uplink succeed, confirming N2/N3 path.",
    "detail_5g_debug_heading": "Debugging Case Study",
    "detail_5g_debug_symptom_label": "Symptom",
    "detail_5g_debug_symptom": "srsRAN gNodeB would exit before establishing an E2 session; logs pointed to E2AP initialization failures.",
    "detail_5g_debug_hypothesis_label": "Hypotheses",
    "detail_5g_debug_hypothesis": "AMF address mismatch, missing `gnb_e2ap.pcap`, or config drift caused by outdated repo versions.",
    "detail_5g_debug_tests_label": "Tests",
    "detail_5g_debug_tests": "Checked AMF reachability via `docker exec open5gs_5gc ping`, verified E2AP PCAP file exists with correct permissions, compared gnb_zmq.yaml versus the known-good template.",
    "detail_5g_debug_fix_label": "Fix",
    "detail_5g_debug_fix": "Rebuilt gNB container with the latest upstream repo, re-generated configs, and re-synchronized the PCAP path/permissions so E2AP parser sees a valid file.",
    "detail_5g_debug_takeaway_label": "Takeaway",
    "detail_5g_debug_takeaway": "Documented the workflow, pinned repo versions, and added scripts so future attempts start from this known-good state.",
    "detail_5g_skills_heading": "Skills Demonstrated",
    "detail_5g_skills_item1": "Container orchestration and container-networking design (Docker Compose, namespaces, NAT) for PR-ready demos.",
    "detail_5g_skills_item2": "RIC/E2 integration and REST debug tooling to prove control plane readiness before exposing the stack to RAN nodes.",
    "detail_5g_skills_item3": "Systematic debugging across AMF, E2AP, and PCAP layers, documenting hypotheses/tests/fixes for the team.",
    "detail_5g_skills_item4": "Reproducible engineering documentation that doubles as a hiring artifact.",
    "detail_5g_artifacts_heading": "Artifacts",
    "detail_5g_artifact_report": "Project report (PDF)",
    "detail_5g_artifact_configs": "Bring-up configs & scripts",
    "detail_5g_artifact_logs": "Debug logs & gNB PCAPs",
    "footer_text": "(C) 2025 Junon Lee. All Rights Reserved."
  },
  "kr": {
    "brand_name": "JUNON LEE",
    "brand_title": "시스템 · AI 연구자",
    "nav_home": "홈",
    "nav_resume": "이력서",
    "nav_portfolio": "포트폴리오",
    "nav_contact": "연락처",
    "profile_name": "이준헌",
    "profile_title": "온디바이스 AI / GPU 아키텍처",
    "profile_summary": "작고 빠른 하드웨어에 맞춘 메모리·GPU 시스템을 설계하여 제품 수준의 ML을 구현합니다.",
    "sidebar_profile_heading": "개인 프로필",
    "sidebar_profile_body": "온디바이스 AI와 GPU 메모리 시스템 연구를 수행하는 연구원 이준헌입니다. 제한된 하드웨어 환경에서도 대규모 모델을 안정적으로 실행할 수 있는 구조적 최적화 방안을 탐구합니다.",
    "sidebar_contact_heading": "연락처",
    "sidebar_contact_email_label": "이메일",
    "sidebar_contact_email_value": "wnsgjs34@gmail.com",
    "sidebar_contact_phone_label": "전화",
    "sidebar_contact_phone_value": "+82-10-7182-9744",
    "sidebar_contact_location_label": "위치",
    "sidebar_contact_location_value": "서울",
    "sidebar_contact_site_label": "사이트",
    "sidebar_contact_site_value": "junon-lee.pages.dev",
    "sidebar_education_heading": "학력",
    "sidebar_education_one": "서울시립대학교 · 전자전기컴퓨터공학과 석사",
    "sidebar_education_one_sub": "2025 - 현재",
    "sidebar_education_two": "서울시립대학교 · 전자전기컴퓨터공학부 학사",
    "sidebar_education_two_sub": "2019 - 2025",
    "sidebar_skills_heading": "스킬",
    "sidebar_skill_one": "온디바이스 AI",
    "sidebar_skill_two": "GPU 가상화",
    "sidebar_skill_three": "Mixture-of-Experts",
    "sidebar_skill_four": "프로파일링",
    "sidebar_skill_five": "기술 문서",
    "sidebar_projects_heading": "프로젝트",
    "sidebar_project_one": "Edge Profiler",
    "sidebar_project_one_sub": "스케줄링 + 텔레메트리",
    "sidebar_project_two": "KV Cache Compressor",
    "sidebar_project_two_sub": "지연 기반 압축",
    "intro_heading": "스펙 시트 개요",
    "intro_body": "페이지 상단 크레딧을 따라가며 각 카드를 클릭하면 프로젝트/논문 상세를 볼 수 있습니다.",
    "intro_cta_resume": "이력서 보기",
    "intro_cta_portfolio": "포트폴리오 보기",
    "intro_cta_contact": "문의하기",
    "home_featured": "추천 작업",
    "home_intro_desc": "엔지니어링 결과와 연구를 필터로 구분하고 각 상세를 확인해보세요.",
    "filter_all": "전체",
    "filter_projects": "프로젝트",
    "filter_research": "연구",
    "work_esmoe_title": "ES-MoE 추론 최적화",
    "work_esmoe_sub": "희소 전문가 루팅 런타임",
    "work_esmoe_date": "2025.05",
    "work_orion_title": "Project Orion 엣지 스택",
    "work_orion_sub": "텔레메트리 + 복구 파이프라인",
    "work_orion_date": "2025.03",
    "work_llm_title": "효율적인 LLM 오프로딩",
    "work_llm_sub": "논문 스타일의 발견",
    "work_llm_date": "2024.11",
    "work_cxl_title": "CXL 기반 티어드 메모리",
    "work_cxl_sub": "다중 티어 배치 정책",
    "work_cxl_date": "2024.08",
    "work_5g_title": "5G O-RAN 시뮬레이션",
    "work_5g_sub": "코어↔RIC↔gNB 검증",
    "work_5g_date": "2025.06",
    "portfolio_intro_title": "포트폴리오 개요",
    "portfolio_intro_desc": "참여하고 수행한 연구와 프로젝트를 정리한 페이지입니다.",
    "portfolio_projects_title": "프로젝트",
    "portfolio_projects_desc": "각 카드가 프로젝트 상세 페이지로 연결됩니다.",
    "portfolio_research_title": "연구",
    "portfolio_research_desc": "논문과 실험 노트를 모아두었습니다.",
    "resume_intro_title": "이력서 스냅샷",
    "resume_intro_desc": "핸즈온 경험, 논문, 수상 기록을 정리했습니다.",
    "resume_experience_title": "경력",
    "resume_exp1_role": "컴퓨터 아키텍처 석사과정 연구원 · ACAS Lab",
    "resume_exp1_period": "2025 - 현재",
    "resume_exp1_desc": "하이브리드 GPU/PIM 클러스터를 위한 추론 최적화와 런타임 자동화를 구축합니다.",
    "resume_exp2_role": "컴퓨터 구조 및 시스템 연구실 인턴  · ACAS Lab",
    "resume_exp2_period": "2024 - 2025",
    "resume_exp2_desc": "KV 캐시 스케줄링 커널과 벤치마크 자동화 코드를 구현했습니다.",
    "resume_exp3_role": "시스템 프로그래밍, 전자전기컴퓨터설계실험2 TA",
    "resume_exp3_period": "2025 2학기",
    "resume_exp3_desc": "전자공학과 학부생 대상 Verilog 실험 수업을 진행 및 강의했습니다.",
    "resume_exp4_role": "대한민국 공군",
    "resume_exp4_period": "2019 8월 - 2021 5월",
    "resume_exp4_desc": "16전투비행단 병장 만기전역",
    "resume_research_title": "연구 하이라이트",
    "resume_pub1_title": "연구 하이라이트 1",
    "resume_pub1_meta": "To be added",
    "resume_pub2_title": "연구 하이라이트 2",
    "resume_pub2_meta": "To be added",
    "resume_pub3_title": "연구 하이라이트 3",
    "resume_pub3_meta": "To be added",
    "resume_projects_title": "대표 빌드",
    "resume_proj1_title": "대표 빌드 1",
    "resume_proj1_desc": "To be added",
    "resume_proj2_title": "대표 빌드 2",
    "resume_proj2_desc": "To be added",
    "resume_awards_title": "수상",
    "resume_award1_title": "차세대통신 혁신융합대학 동계 현장실습 | CAN 통신 기반 프로젝트 우수상",
    "resume_award1_desc": "동계 현장실습 산학 프로젝트에서 CAN 통신 주제로 우수상 수상, 2025.01",
    "resume_award2_title": "인천광역시 대학생 시정 정책 제안·발표대회 최우수상",
    "resume_award2_desc": "시정 정책 제안 발표로 최우수상 수상, 2019.08",
    "contact_intro_title": "문의 안내",
    "contact_intro_desc": "방문, 공동 연구, 채용 제안 모두 환영합니다.",
    "contact_card_lab_title": "랩 방문",
    "contact_card_lab_desc": "서울특별시 서울시립대로 163, 정보기술관 613호",
    "contact_card_talks_title": "조교/실험 관련",
    "contact_card_talks_desc": "이메일 혹은 전화로 연락바랍니다.",
    "contact_card_collab_title": "협업",
    "contact_card_collab_desc": "관련 분야 공동연구에 항상 열려있습니다.",
    "contact_card_career_title": "Recruiting",
    "contact_card_career_desc": "AI 시스템, GPU 아키텍처, 시스템 최적화 분야의 R&D 포지션 관련 제안을 받고 있습니다",
    "contact_form_title": "간단한 메시지",
    "contact_form_desc": "어떤 주제로 연락하실지 적어주시면 빠르게 회신합니다.",
    "contact_form_name": "이름",
    "contact_form_email": "이메일",
    "contact_form_message": "프로젝트 내용",
    "contact_form_cta": "보내기",
    "detail_label_role": "역할",
    "detail_label_timeline": "기간",
    "detail_label_stack": "기술",
    "detail_overview_heading": "개요",
    "detail_contribution_heading": "핵심 기여",
    "detail_findings_heading": "연구 결과",
    "detail_outcome_heading": "임팩트",
    "detail_btn_visit": "사이트",
    "detail_btn_deck": "자료",
    "detail_btn_paper": "논문",
    "detail_btn_slides": "슬라이드",
    "detail_esmoe_title": "ES-MoE 추론 최적화",
    "detail_esmoe_subtitle": "엣지 GPU 전문가 스케일링",
    "detail_esmoe_role": "리드 연구자",
    "detail_esmoe_timeline": "2024 - 2025",
    "detail_esmoe_stack": "PyTorch, CUDA Graphs, Triton",
    "detail_esmoe_overview": "희소 전문가 라우팅과 관측 스택으로 저지연 추론을 유지합니다.",
    "detail_esmoe_point1": "40µs 내의 전문 선택 로직.",
    "detail_esmoe_point2": "스트리밍 KV 캐시 압축으로 2배 처리량.",
    "detail_esmoe_point3": "전문가별 사용률 대시보드.",
    "detail_esmoe_outcome": "데모 로봇에서 38% 지연 감소.",
    "detail_orion_title": "Project Orion 엣지",
    "detail_orion_subtitle": "자율 드론 텔레메트리",
    "detail_orion_role": "시스템 엔지니어",
    "detail_orion_timeline": "2023 - 2024",
    "detail_orion_stack": "Rust, gRPC, Prometheus, Azure IoT",
    "detail_orion_overview": "불안정한 네트워크에서도 GPU와 미션 데이터 동기화합니다.",
    "detail_orion_point1": "15분 통신 두절 방어 버퍼링.",
    "detail_orion_point2": "GPU 열 스로틀 즉시 노출.",
    "detail_orion_point3": "미션 재생 대시보드 제공.",
    "detail_orion_outcome": "지원 이슈 45% 감소, 12개 파일럿에서 무인 운영.",
    "detail_llm_title": "효율적인 LLM 오프로딩",
    "detail_llm_subtitle": "모바일 GPU 파이프라인",
    "detail_llm_role": "제1저자",
    "detail_llm_timeline": "2024",
    "detail_llm_stack": "CUDA, PyTorch, FlexGen, TensorRT",
    "detail_llm_overview": "메모리 예산을 지키면서 긴 시퀀스를 처리하는 하이브리ッド 실행.",
    "detail_llm_point1": "프리필·디코드 겹침 모델.",
    "detail_llm_point2": "6GB VRAM 내 캐시 축출 유지.",
    "detail_llm_point3": "Jetson Orin에서 1.6배 처리량.",
    "detail_llm_outcome": "모바일 LLM 배포 가이드로 활용.",
    "detail_cxl_title": "CXL 기반 티어드 메모리",
    "detail_cxl_subtitle": "HBM + CXL 클러스터",
    "detail_cxl_role": "공저자",
    "detail_cxl_timeline": "2023",
    "detail_cxl_stack": "CXL 시뮬레이터, Python, NVProf",
    "detail_cxl_overview": "CXL 확장기를 갖춘 다중 티어 시스템의 KV 캐시 정책을 탐색합니다.",
    "detail_cxl_point1": "텐서를 CXL로 옮길지 결정하는 지연 예측.",
    "detail_cxl_point2": "큐 지연 스파이크에 반응하는 컨트롤러.",
    "detail_cxl_point3": "CXL+HBM 혼합으로 27% 비용 절감.",
    "detail_cxl_outcome": "산업 파트너 로드맵에 반영.",
    "detail_5g_title": "5G O-RAN end-to-end simulation",
    "detail_5g_subtitle": "Open5GS · srsRAN · O-RAN SC 연동",
    "detail_5g_role": "시스템 엔지니어",
    "detail_5g_timeline": "2025",
    "detail_5g_stack": "Open5GS, srsRAN, O-RAN SC RIC",
    "detail_5g_overview": "Open5GS(코어), srsRAN gNB/UE, O-RAN SC RIC을 E2로 연결해 전체 5G 스택을 재구성했고, 구성 파일·도커 네트워킹·네임스페이스 등 브링업 산출물을 그대로 기록했습니다.",
    "detail_5g_point1": "`docker compose up 5gc`, `./gnb -c gnb_zmq.yaml`, `./srsue ue_zmq.conf`를 스크립트화하여 네임스페이스·포트·NAT을 조율하면서 Core부터 UE까지의 등록을 검증했습니다.",
    "detail_5g_point2": "O-RAN SC RIC을 실행하고 gNB와 연결하여, E2 세션과 제어 평면 핸드셰이크가 컨테이너가 올라오자마자 안정적으로 이루어지도록 확인했습니다.",
    "detail_5g_point3": "gNB 시작 오류는 AMF 연결, YAML/PCAP 설정, 권한을 점검하면서 파악했고, INI 파서 문제 발생 시 최신 빌드로 전환해 재현 가능한 워크플로로 고정했습니다.",
    "detail_5g_outcome": "명령어·설정·디버깅 로그를 모두 문서화해 새로운 RIC 실험자가 파일을 찾느라 시간 낭비하지 않고 바로 사이클을 재구성할 수 있게 했습니다.",
    "detail_5g_arch_heading": "System Architecture",
    "detail_5g_arch_body": "UE (srsRAN) ↔ gNB (srsRAN) ↔ Open5GS Core with the O-RAN SC RIC attached via 5G RAN E2 interfaces; every service runs in Docker Compose, networks isolated with namespaces, NAT rules, and service labels.",
    "detail_5g_pipeline_heading": "Bring-up Pipeline",
    "detail_5g_pipeline_step1": "Start Open5GS 5gc container (`docker compose up 5gc`), confirm AMF/SMF/NSSF services and northbound gNodeB/IP reachability.",
    "detail_5g_pipeline_step2": "Bring up the O-RAN SC RIC so E2AP stacks can register globally; inspect `ric` logs for heartbeat and set RAN node config to open E2 connections.",
    "detail_5g_pipeline_step3": "Launch srsRAN gNB with E2 enabled (`./gnb -c gnb_zmq.yaml e2`) in the same namespace, verifying gNB local interfaces plus correct PCAP path/version.",
    "detail_5g_pipeline_step4": "Activate srsRAN UE (`./srsue ue_zmq.conf`), observe NAS attach, then run `ping`/`traceroute` through the namespace to prove UE ↔ Core connectivity.",
    "detail_5g_validation_heading": "Validation & Evidence",
    "detail_5g_validation_item1": "Open5GS health check shows AMF/NSSF threads bound to 38412 and publishes service stats before gNB startup.",
    "detail_5g_validation_item2": "RIC reports E2 session establishment when the gNB registers, so the control plane handshake was verified via the REST debug API.",
    "detail_5g_validation_item3": "UE attaches and receives IP; `ping`/`iperf` from the UE namespace to the core uplink succeed, confirming N2/N3 path.",
    "detail_5g_debug_heading": "Debugging Case Study",
    "detail_5g_debug_symptom_label": "Symptom",
    "detail_5g_debug_symptom": "srsRAN gNodeB would exit before establishing an E2 session; logs pointed to E2AP initialization failures.",
    "detail_5g_debug_hypothesis_label": "Hypotheses",
    "detail_5g_debug_hypothesis": "AMF address mismatch, missing `gnb_e2ap.pcap`, or config drift caused by outdated repo versions.",
    "detail_5g_debug_tests_label": "Tests",
    "detail_5g_debug_tests": "Checked AMF reachability via `docker exec open5gs_5gc ping`, verified E2AP PCAP file exists with correct permissions, compared gnb_zmq.yaml versus the known-good template.",
    "detail_5g_debug_fix_label": "Fix",
    "detail_5g_debug_fix": "Rebuilt gNB container with the latest upstream repo, re-generated configs, and re-synchronized the PCAP path/permissions so E2AP parser sees a valid file.",
    "detail_5g_debug_takeaway_label": "Takeaway",
    "detail_5g_debug_takeaway": "Documented the workflow, pinned repo versions, and added scripts so future attempts start from this known-good state.",
    "detail_5g_skills_heading": "Skills Demonstrated",
    "detail_5g_skills_item1": "Container orchestration and container-networking design (Docker Compose, namespaces, NAT) for PR-ready demos.",
    "detail_5g_skills_item2": "RIC/E2 integration and REST debug tooling to prove control plane readiness before exposing the stack to RAN nodes.",
    "detail_5g_skills_item3": "Systematic debugging across AMF, E2AP, and PCAP layers, documenting hypotheses/tests/fixes for the team.",
    "detail_5g_skills_item4": "Reproducible engineering documentation that doubles as a hiring artifact.",
    "detail_5g_artifacts_heading": "Artifacts",
    "detail_5g_artifact_report": "Project report (PDF)",
    "detail_5g_artifact_configs": "Bring-up configs & scripts",
    "detail_5g_artifact_logs": "Debug logs & gNB PCAPs",
    "footer_text": "(C) 2025 Junon Lee. All Rights Reserved."
  },
  "jp": {
    "brand_name": "JUNON LEE",
    "brand_title": "システム・AI研究者",
    "nav_home": "ホーム",
    "nav_resume": "履歴書",
    "nav_portfolio": "ポートフォリオ",
    "nav_contact": "連絡",
    "profile_name": "イ・ジュノン (李 俊憲)",
    "profile_title": "On-device AI / GPU バーチャライゼーション",
    "profile_summary": "ハードウェアに最適化されたMLを設計し、実運用レベルでスケールさせるシステムを構築します。",
    "sidebar_profile_heading": "個人プロフィール",
    "sidebar_profile_body": "オンデバイスAIとGPUメモリシステムの研究を行っている研究者です。限られたハードウェア環境でも大規模モデルを安定して動作させるための最適化手法を探究しています。",
    "sidebar_contact_heading": "コンタクト",
    "sidebar_contact_email_label": "メール",
    "sidebar_contact_email_value": "wnsgjs34@gmail.com",
    "sidebar_contact_phone_label": "電話",
    "sidebar_contact_phone_value": "+82-10-7182-9744",
    "sidebar_contact_location_label": "場所",
    "sidebar_contact_location_value": "ソウル",
    "sidebar_contact_site_label": "サイト",
    "sidebar_contact_site_value": "junon-lee.pages.dev",
    "sidebar_education_heading": "学歴",
    "sidebar_education_one": "University of Seoul · M.S. Electrical and Computer Engineering",
    "sidebar_education_one_sub": "2025 - 現在",
    "sidebar_education_two": "University of Seoul · B.S. Electrical and Computer Engineering",
    "sidebar_education_two_sub": "2019 - 2025",
    "sidebar_skills_heading": "スキル",
    "sidebar_skill_one": "オンデバイスAI",
    "sidebar_skill_two": "GPUバーチャライゼーション",
    "sidebar_skill_three": "Mixture-of-Experts",
    "sidebar_skill_four": "プロファイリング",
    "sidebar_skill_five": "技術ドキュメント",
    "sidebar_projects_heading": "プロジェクト",
    "sidebar_project_one": "Edge Profiler",
    "sidebar_project_one_sub": "スケジューリング・テレメトリ",
    "sidebar_project_two": "KV Cache Compressor",
    "sidebar_project_two_sub": "レイテンシー圧縮",
    "intro_heading": "スペックシート概要",
    "intro_body": "このページから各カードでプロジェクトや論文の詳細ページへ移動できます。",
    "intro_cta_resume": "履歴書を見る",
    "intro_cta_portfolio": "ポートフォリオを見る",
    "intro_cta_contact": "連絡を送る",
    "home_featured": "注目の作品",
    "home_intro_desc": "エンジニアリング成果と研究をフィルタして、各詳細ページをご覧ください。",
    "filter_all": "全て",
    "filter_projects": "プロジェクト",
    "filter_research": "研究",
    "work_esmoe_title": "ES-MoE 推論最適化",
    "work_esmoe_sub": "スパースエキスパートルーティング",
    "work_esmoe_date": "2025.05",
    "work_orion_title": "Project Orion エッジスタック",
    "work_orion_sub": "テレメトリ＋復旧パイプライン",
    "work_orion_date": "2025.03",
    "work_llm_title": "効率的なLLMオフローディング",
    "work_llm_sub": "ジャーナルスタイルの発見",
    "work_llm_date": "2024.11",
    "work_cxl_title": "CXL対応のティアドメモリ",
    "work_cxl_sub": "マルチティア配置ポリシー",
    "work_cxl_date": "2024.08",
    "work_5g_title": "5G O-RAN ネットワークシミュレーション",
    "work_5g_sub": "コア↔RIC↔gNB 構築",
    "work_5g_date": "2025.06",
    "portfolio_intro_title": "ポートフォリオの概要",
    "portfolio_intro_desc": "これまでに取り組んできた研究やプロジェクトをまとめたページです。",
    "portfolio_projects_title": "エンジニアリングプロジェクト",
    "portfolio_projects_desc": "各タイルがプロジェクトの詳細ページにリンクします。",
    "portfolio_research_title": "研究と論文",
    "portfolio_research_desc": "これまでの論文および実験ノートを整理して掲載しています。",
    "resume_intro_title": "履歴書のスナップショット",
    "resume_intro_desc": "実務経験、研究、受賞をまとめたページです。",
    "resume_experience_title": "経験",
    "resume_exp1_role": "大学院研究員 · ACAS Lab",
    "resume_exp1_period": "2025 - 現在",
    "resume_exp1_desc": "ハイブリッドGPU/PIMクラスタでの推論最適化とランタイム自動化を担当。",
    "resume_exp2_role": "システムエンジニアインターン · FlexGen",
    "resume_exp2_period": "2024年夏",
    "resume_exp2_desc": "KVキャッシュスケジューリングカーネルとベンチマーク自動化を実装。",
    "resume_exp3_role": "システムプログラミングTA",
    "resume_exp3_period": "2024",
    "resume_exp3_desc": "40名以上にVerilog、GPUシミュレーター、OS計測の演習を指導。",
    "resume_exp4_role": "Airforce, Republic of Korea",
    "resume_exp4_period": "Aug 2019 - May 2021",
    "resume_exp4_desc": "Staff sergeant/ honorable discharge",
    "resume_research_title": "研究ハイライト",
    "resume_pub1_title": "研究ハイライト 1",
    "resume_pub1_meta": "To be added",
    "resume_pub2_title": "研究ハイライト 2",
    "resume_pub2_meta": "To be added",
    "resume_pub3_title": "研究ハイライト 3",
    "resume_pub3_meta": "To be added",
    "resume_projects_title": "代表プロジェクト",
    "resume_proj1_title": "代表プロジェクト 1",
    "resume_proj1_desc": "To be added",
    "resume_proj2_title": "代表プロジェクト 2",
    "resume_proj2_desc": "To be added",
    "resume_awards_title": "受賞 & 認知",
    "resume_award1_title": "次世代通信 イノベーション融合大学（冬季インターン）｜CAN通信プロジェクト 優秀賞",
    "resume_award1_desc": "冬季の産学連携インターンで、CAN通信プロジェクトにより優秀賞を受賞。 2025.01",
    "resume_award2_title": "仁川 大学生 政策提案・発表大会 最優秀賞",
    "resume_award2_desc": "市政の政策提案発表で最優秀賞を受賞。2019.08",
    "contact_intro_title": "お問い合わせ",
    "contact_intro_desc": "訪問、講演、共同研究すべて歓迎です。",
    "contact_card_lab_title": "研究室訪問",
    "contact_card_lab_desc": "ソウル特別市 ソウル市立大学 163 情報技術館 613号室",
    "contact_card_talks_title": "TA／実験関連",
    "contact_card_talks_desc": "メールまたは電話でご連絡ください。",
    "contact_card_collab_title": "共同研究",
    "contact_card_collab_desc": "関連分野の共同研究を随時受け付けています。",
    "contact_card_career_title": "リクルーティング",
    "contact_card_career_desc": "AIシステム、GPUアーキテクチャ、システム最適化に関するR&Dポジションのご提案を歓迎します。",
    "contact_form_title": "クイックメッセージ",
    "contact_form_desc": "話したいトピックを記入してください。すぐに返信します。",
    "contact_form_name": "お名前",
    "contact_form_email": "メール",
    "contact_form_message": "ご相談内容",
    "contact_form_cta": "送信",
    "detail_label_role": "役割",
    "detail_label_timeline": "期間",
    "detail_label_stack": "技術",
    "detail_overview_heading": "概要",
    "detail_contribution_heading": "主な貢献",
    "detail_findings_heading": "研究結果",
    "detail_outcome_heading": "インパクト",
    "detail_btn_visit": "サイト",
    "detail_btn_deck": "資料",
    "detail_btn_paper": "論文",
    "detail_btn_slides": "スライド",
    "detail_esmoe_title": "ES-MoE 推論最適化",
    "detail_esmoe_subtitle": "エッジGPU向け専門スケーリング",
    "detail_esmoe_role": "リード研究者",
    "detail_esmoe_timeline": "2024 - 2025",
    "detail_esmoe_stack": "PyTorch, CUDA Graphs, Triton",
    "detail_esmoe_overview": "スパース専門ルーティングとモニタリングスタックで小型GPUでも低レイテンシを実現。",
    "detail_esmoe_point1": "レイテンシを意識した専門選択を40µsで実行。",
    "detail_esmoe_point2": "ストリーミングKVキャッシュ圧縮で2倍のスループット達成。",
    "detail_esmoe_point3": "ダッシュボードで専門別利用率を可視化。",
    "detail_esmoe_outcome": "デモロボットで38%のレイテンシ削減。",
    "detail_orion_title": "Project Orion エッジ",
    "detail_orion_subtitle": "自律ドローンのテレメトリ",
    "detail_orion_role": "システムエンジニア",
    "detail_orion_timeline": "2023 - 2024",
    "detail_orion_stack": "Rust, gRPC, Prometheus, Azure IoT",
    "detail_orion_overview": "不安定なネットワークでもGPUメトリクスとミッションデータを同期。",
    "detail_orion_point1": "15分の接続切断を耐えるバッファ。",
    "detail_orion_point2": "GPU熱スロットルを即時表示。",
    "detail_orion_point3": "ミッション再生ダッシュボード提供。",
    "detail_orion_outcome": "サポート件数45%減、12件のパイロットで自主運用。",
    "detail_llm_title": "効率的なLLMオフローディング",
    "detail_llm_subtitle": "モバイルGPUパイプライン",
    "detail_llm_role": "第一著者",
    "detail_llm_timeline": "2024",
    "detail_llm_stack": "CUDA, PyTorch, FlexGen, TensorRT",
    "detail_llm_overview": "メモリ予算を守りながら長いシーケンスを維持するハイブリッド実行を定義。",
    "detail_llm_point1": "プリフィル・デコードを重ねるモデルを導出。",
    "detail_llm_point2": "6GB VRAM内で精度を維持するキャッシュ排出。",
    "detail_llm_point3": "Jetson Orinで1.6倍スループット。",
    "detail_llm_outcome": "モバイルLLM展開ガイドとして活用。",
    "detail_cxl_title": "CXL対応ティアードメモリ",
    "detail_cxl_subtitle": "HBM + CXLクラスタ",
    "detail_cxl_role": "共著者",
    "detail_cxl_timeline": "2023",
    "detail_cxl_stack": "CXLシミュレータ, Python, NVProf",
    "detail_cxl_overview": "CXL拡張を備えた多段階システムでKVキャッシュ移動ポリシーを探る。",
    "detail_cxl_point1": "CXLプールへの転送時の遅延予測器。",
    "detail_cxl_point2": "キュー遅延に応答するコントローラ。",
    "detail_cxl_point3": "CXL+HBM混合で27%コスト削減。",
    "detail_cxl_outcome": "産業パートナーのロードマップに貢献。",
    "detail_5g_title": "5G O-RAN エンドツーエンドシミュレーション",
    "detail_5g_subtitle": "Open5GS・srsRAN・O-RAN SC を接続",
    "detail_5g_role": "システムエンジニア",
    "detail_5g_timeline": "2025",
    "detail_5g_stack": "Open5GS, srsRAN, O-RAN SC RIC",
    "detail_5g_overview": "Open5GS（コア）、srsRAN gNB/UE、O-RAN SC RIC を E2 でつなぎ、構成ファイルやコンテナネットワーク、名前空間などのブリングアップ成果を記録した 5G スタックを再現しました。",
    "detail_5g_point1": "`docker compose up 5gc`、`./gnb -c gnb_zmq.yaml`、`./srsue ue_zmq.conf` をスクリプト化し、名前空間・ポート・NAT を整えてコアから UE までの登録を検証しました。",
    "detail_5g_point2": "O-RAN SC RIC を起動し、gNB と組み合わせて E2 セッションの制御平面ハンドシェイクがコンテナ起動直後に安定することを確認しました。",
    "detail_5g_point3": "gNB 起動失敗は AMF 到達性、YAML／PCAP 設定、パーミッションを分離して診断し、INI パーサー問題では既知の安定版に戻しました。",
    "detail_5g_outcome": "コマンド・設定・デバッグ記録を残し、新しい RIC チームが Core→RIC→UE のループを再現できるようにしました。",
    "detail_5g_arch_heading": "System Architecture",
    "detail_5g_arch_body": "UE (srsRAN) ↔ gNB (srsRAN) ↔ Open5GS Core with the O-RAN SC RIC attached via 5G RAN E2 interfaces; every service runs in Docker Compose, networks isolated with namespaces, NAT rules, and service labels.",
    "detail_5g_pipeline_heading": "Bring-up Pipeline",
    "detail_5g_pipeline_step1": "Start Open5GS 5gc container (`docker compose up 5gc`), confirm AMF/SMF/NSSF services and northbound gNodeB/IP reachability.",
    "detail_5g_pipeline_step2": "Bring up the O-RAN SC RIC so E2AP stacks can register globally; inspect `ric` logs for heartbeat and set RAN node config to open E2 connections.",
    "detail_5g_pipeline_step3": "Launch srsRAN gNB with E2 enabled (`./gnb -c gnb_zmq.yaml e2`) in the same namespace, verifying gNB local interfaces plus correct PCAP path/version.",
    "detail_5g_pipeline_step4": "Activate srsRAN UE (`./srsue ue_zmq.conf`), observe NAS attach, then run `ping`/`traceroute` through the namespace to prove UE ↔ Core connectivity.",
    "detail_5g_validation_heading": "Validation & Evidence",
    "detail_5g_validation_item1": "Open5GS health check shows AMF/NSSF threads bound to 38412 and publishes service stats before gNB startup.",
    "detail_5g_validation_item2": "RIC reports E2 session establishment when the gNB registers, so the control plane handshake was verified via the REST debug API.",
    "detail_5g_validation_item3": "UE attaches and receives IP; `ping`/`iperf` from the UE namespace to the core uplink succeed, confirming N2/N3 path.",
    "detail_5g_debug_heading": "Debugging Case Study",
    "detail_5g_debug_symptom_label": "Symptom",
    "detail_5g_debug_symptom": "srsRAN gNodeB would exit before establishing an E2 session; logs pointed to E2AP initialization failures.",
    "detail_5g_debug_hypothesis_label": "Hypotheses",
    "detail_5g_debug_hypothesis": "AMF address mismatch, missing `gnb_e2ap.pcap`, or config drift caused by outdated repo versions.",
    "detail_5g_debug_tests_label": "Tests",
    "detail_5g_debug_tests": "Checked AMF reachability via `docker exec open5gs_5gc ping`, verified E2AP PCAP file exists with correct permissions, compared gnb_zmq.yaml versus the known-good template.",
    "detail_5g_debug_fix_label": "Fix",
    "detail_5g_debug_fix": "Rebuilt gNB container with the latest upstream repo, re-generated configs, and re-synchronized the PCAP path/permissions so E2AP parser sees a valid file.",
    "detail_5g_debug_takeaway_label": "Takeaway",
    "detail_5g_debug_takeaway": "Documented the workflow, pinned repo versions, and added scripts so future attempts start from this known-good state.",
    "detail_5g_skills_heading": "Skills Demonstrated",
    "detail_5g_skills_item1": "Container orchestration and container-networking design (Docker Compose, namespaces, NAT) for PR-ready demos.",
    "detail_5g_skills_item2": "RIC/E2 integration and REST debug tooling to prove control plane readiness before exposing the stack to RAN nodes.",
    "detail_5g_skills_item3": "Systematic debugging across AMF, E2AP, and PCAP layers, documenting hypotheses/tests/fixes for the team.",
    "detail_5g_skills_item4": "Reproducible engineering documentation that doubles as a hiring artifact.",
    "detail_5g_artifacts_heading": "Artifacts",
    "detail_5g_artifact_report": "Project report (PDF)",
    "detail_5g_artifact_configs": "Bring-up configs & scripts",
    "detail_5g_artifact_logs": "Debug logs & gNB PCAPs",
    "footer_text": "(C) 2025 Junon Lee. All Rights Reserved."
  }
};
