window.TRANSLATION_DATA = { en: JSON.parse(`{
  "brand_name": "Your Name",
  "brand_title": "Systems & AI Researcher",

  "nav_home": "Home",
  "nav_resume": "Resume",
  "nav_portfolio": "Portfolio",
  "nav_contact": "Contact",

  "profile_name": "Your Name",
  "profile_title": "On-device AI / GPU Virtualization",
  "profile_summary": "I engineer hardware-conscious ML systems that stay lean yet scale to production workloads.",

  "sidebar_profile_heading": "Personal profile",
  "sidebar_profile_body": "Adaptive thinker, systems improviser, and storyteller who keeps big missions grounded in prototypes and metrics.",
  "sidebar_contact_heading": "Contact",
  "sidebar_contact_email_label": "Email",
  "sidebar_contact_email_value": "hello@example.com",
  "sidebar_contact_phone_label": "Phone",
  "sidebar_contact_phone_value": "+82-10-0000-0000",
  "sidebar_contact_location_label": "Location",
  "sidebar_contact_location_value": "Seoul / Daejeon, South Korea",
  "sidebar_contact_site_label": "Website",
  "sidebar_contact_site_value": "example.com",
  "sidebar_education_heading": "Education",
  "sidebar_education_one": "KAIST 쨌 M.S. Computer Science",
  "sidebar_education_one_sub": "2023 - 2025",
  "sidebar_education_two": "KAIST 쨌 B.S. Electrical Engineering",
  "sidebar_education_two_sub": "2019 - 2023",
  "sidebar_skills_heading": "Skills",
  "sidebar_skill_one": "On-device AI",
  "sidebar_skill_two": "GPU virtualization",
  "sidebar_skill_three": "Mixture-of-experts",
  "sidebar_skill_four": "Profiling & tooling",
  "sidebar_skill_five": "Technical writing",
  "sidebar_projects_heading": "Highlighted projects",
  "sidebar_project_one": "Edge Profiler",
  "sidebar_project_one_sub": "Scheduling + telemetry stack",
  "sidebar_project_two": "KV Cache Compressor",
  "sidebar_project_two_sub": "Latency-aware compression",

  "intro_heading": "Spec sheet overview",
  "intro_body": "The portfolio is anchored by this page. Every block below links to a more detailed project or publication entry.",
  "intro_cta_resume": "Open resume",
  "intro_cta_portfolio": "View portfolio",
  "intro_cta_contact": "Drop a note",

  "home_featured": "Featured work",
  "home_intro_desc": "Filter between engineering deliverables and research write-ups, then click a card to explore the case study.",
  "filter_all": "All",
  "filter_projects": "Projects",
  "filter_research": "Research",

  "work_esmoe_title": "ES-MoE inference optimizer",
  "work_esmoe_sub": "Sparse expert routing runtime",
  "work_esmoe_date": "2025.05",
  "work_orion_title": "Project Orion edge stack",
  "work_orion_sub": "Telemetry + remediation pipeline",
  "work_orion_date": "2025.03",
  "work_llm_title": "Efficient LLM offloading",
  "work_llm_sub": "Journal-style findings",
  "work_llm_date": "2024.11",
  "work_cxl_title": "CXL-aware tiered memory",
  "work_cxl_sub": "Multi-tier placement policy",
  "work_cxl_date": "2024.08",

  "portfolio_intro_title": "Portfolio overview",
  "portfolio_intro_desc": "Engineering builds and research publications are collected here with placeholder summaries.",
  "portfolio_projects_title": "Engineering projects",
  "portfolio_projects_desc": "Each tile routes to a project detail page with research-worthy copy.",
  "portfolio_research_title": "Research & publications",
  "portfolio_research_desc": "Summaries of peer-reviewed work and notes from recent experiments.",

  "resume_intro_title": "Resume snapshot",
  "resume_intro_desc": "This page lists the hands-on experience, publications, and awards that kept the home hero concise.",
  "resume_experience_title": "Experience",
  "resume_exp1_role": "Graduate researcher 쨌 ACAS Lab",
  "resume_exp1_period": "2025 - Present",
  "resume_exp1_desc": "Building inference optimizers and runtime automation for hybrid GPU/PIM clusters.",
  "resume_exp2_role": "Systems engineer intern 쨌 FlexGen",
  "resume_exp2_period": "Summer 2024",
  "resume_exp2_desc": "Implemented KV cache scheduling kernels and benchmark automation on Blackwell hardware.",
  "resume_exp3_role": "Teaching assistant 쨌 Systems programming",
  "resume_exp3_period": "2024",
  "resume_exp3_desc": "Led labs covering Verilog, GPU simulation, and OS instrumentation for 40+ students.",
  "resume_research_title": "Research highlights",
  "resume_pub1_title": "ES-MoE: Expert scaling for edge inference",
  "resume_pub1_meta": "Under review 쨌 First author",
  "resume_pub2_title": "Memory-aware LLM offloading",
  "resume_pub2_meta": "MLSys 2024 쨌 Co-author",
  "resume_pub3_title": "CXL-aware tiering policies",
  "resume_pub3_meta": "HPCA 2023 쨌 Co-author",
  "resume_projects_title": "Selected builds",
  "resume_proj1_title": "Project Orion telemetry pipeline",
  "resume_proj1_desc": "Fault-tolerant synchronization and real-time health scoring for fleets.",
  "resume_proj2_title": "FlexBench profiling suite",
  "resume_proj2_desc": "Open-source tooling to capture latency and power for each LLM component.",
  "resume_awards_title": "Awards & recognition",
  "resume_award1_title": "KAIST presidential scholarship",
  "resume_award1_desc": "Full scholarship for top 1% researchers",
  "resume_award2_title": "Outstanding teaching assistant",
  "resume_award2_desc": "System Programming 쨌 Spring 2024",

  "contact_intro_title": "Contact guide",
  "contact_intro_desc": "Share a quick note or book a visit. Below are the doors that stay open.",
  "contact_card_lab_title": "Lab visits",
  "contact_card_lab_desc": "Schedule walkthroughs or join weekly research demos.",
  "contact_card_talks_title": "Talks & panels",
  "contact_card_talks_desc": "Available for short talks on on-device AI or GPU memory orchestration.",
  "contact_card_collab_title": "Collaboration",
  "contact_card_collab_desc": "Open to joint projects on inference tooling, offloading, or systems programming.",
  "contact_form_title": "Quick message",
  "contact_form_desc": "Drop the topic you want to chat about and I will reply soon.",
  "contact_form_name": "Your name",
  "contact_form_email": "Work email",
  "contact_form_message": "Reason for writing",
  "contact_form_cta": "Send message",

  "detail_label_role": "Role",
  "detail_label_timeline": "Timeline",
  "detail_label_stack": "Stack",
  "detail_overview_heading": "Overview",
  "detail_contribution_heading": "Key contributions",
  "detail_findings_heading": "Research findings",
  "detail_outcome_heading": "Impact",
  "detail_btn_visit": "Visit site",
  "detail_btn_deck": "Download deck",
  "detail_btn_paper": "Read paper",
  "detail_btn_slides": "View slides",

  "detail_esmoe_title": "ES-MoE inference optimizer",
  "detail_esmoe_subtitle": "Expert-scaling toolkit for edge GPUs",
  "detail_esmoe_role": "Lead researcher",
  "detail_esmoe_timeline": "2024 - 2025",
  "detail_esmoe_stack": "PyTorch, CUDA Graphs, Triton",
  "detail_esmoe_overview": "Optimized sparse MoE routing with latency-aware placement and instrumentation for small GPU pods.",
  "detail_esmoe_point1": "Designed a 40쨉s expert selection that respects device bandwidth.",
  "detail_esmoe_point2": "Implemented streaming KV cache compression with 2횞 throughput vs. PyTorch baseline.",
  "detail_esmoe_point3": "Delivered dashboards showing per-expert utilization across deployments.",
  "detail_esmoe_outcome": "Reduced end-to-end latency by 38% on ACAS Lab robots.",

  "detail_orion_title": "Project Orion edge stack",
  "detail_orion_subtitle": "Telemetry + resilience for autonomous drones",
  "detail_orion_role": "Systems engineer",
  "detail_orion_timeline": "2023 - 2024",
  "detail_orion_stack": "Rust, gRPC, Prometheus, Azure IoT",
  "detail_orion_overview": "Built reliable pipelines syncing GPU metrics and mission data even over flaky links.",
  "detail_orion_point1": "Shipped adaptive buffering surviving 15-minute disconnects.",
  "detail_orion_point2": "Exposed GPU thermal throttling through profiler hooks.",
  "detail_orion_point3": "Packaged mission replay dashboards for field teams.",
  "detail_orion_outcome": "Cut support escalations by 45% and enabled 12 pilot programs.",

  "detail_llm_title": "Efficient LLM offloading",
  "detail_llm_subtitle": "Pipeline scheduling for mobile GPUs",
  "detail_llm_role": "First author",
  "detail_llm_timeline": "2024",
  "detail_llm_stack": "CUDA, PyTorch, FlexGen, TensorRT",
  "detail_llm_overview": "Quantifies hybrid CPU/GPU execution that preserves large sequences inside memory budgets.",
  "detail_llm_point1": "Derived overlapping prefill/decode models under bandwidth limits.",
  "detail_llm_point2": "Introduced progressive cache eviction within 6 GB VRAM.",
  "detail_llm_point3": "Benchmarked on Jetson Orin with 1.6횞 throughput gains.",
  "detail_llm_outcome": "Spotlight talk; widely cited for mobile LLM deployments.",

  "detail_cxl_title": "CXL-aware tiered memory",
  "detail_cxl_subtitle": "Dynamic placement for HBM + CXL clusters",
  "detail_cxl_role": "Co-author",
  "detail_cxl_timeline": "2023",
  "detail_cxl_stack": "CXL simulator, Python, NVProf",
  "detail_cxl_overview": "Modeled multi-tier nodes with CXL expanders and explored cache migration heuristics.",
  "detail_cxl_point1": "Proposed latency predictors for spilling tensors to CXL pools.",
  "detail_cxl_point2": "Implemented a feedback controller reacting to queueing spikes.",
  "detail_cxl_point3": "Achieved 27% better cost-per-query by mixing CXL and HBM.",
  "detail_cxl_outcome": "Influenced hardware roadmaps with industry partners.",

  "footer_text": "(C) 2025 Your Name. All Rights Reserved."
}
`), kr: JSON.parse(`{
  "brand_name": "홍길동",
  "brand_title": "시스템 · AI 연구자",

  "nav_home": "홈",
  "nav_resume": "이력서",
  "nav_portfolio": "포트폴리오",
  "nav_contact": "연락",

  "profile_name": "홍길동",
  "profile_title": "온디바이스 AI / GPU 가상화",
  "profile_summary": "작고 빠른 하드웨어에 맞춘 메모리·GPU 시스템을 설계하여 제품 수준의 ML을 구현합니다.",

  "sidebar_profile_heading": "개인 프로필",
  "sidebar_profile_body": "시스템 설계와 스토리텔링, 프로토타입 제작으로 복잡한 연구를 실행 가능한 결과로 바꿉니다.",
  "sidebar_contact_heading": "연락처",
  "sidebar_contact_email_label": "이메일",
  "sidebar_contact_email_value": "hello@example.com",
  "sidebar_contact_phone_label": "전화",
  "sidebar_contact_phone_value": "+82-10-0000-0000",
  "sidebar_contact_location_label": "위치",
  "sidebar_contact_location_value": "서울 · 대전",
  "sidebar_contact_site_label": "사이트",
  "sidebar_contact_site_value": "example.com",
  "sidebar_education_heading": "학력",
  "sidebar_education_one": "KAIST · 전산학 석사",
  "sidebar_education_one_sub": "2023 - 2025",
  "sidebar_education_two": "KAIST · 전기전자공학 학사",
  "sidebar_education_two_sub": "2019 - 2023",
  "sidebar_skills_heading": "스킬",
  "sidebar_skill_one": "온디바이스 AI",
  "sidebar_skill_two": "GPU 가상화",
  "sidebar_skill_three": "Mixture-of-Experts",
  "sidebar_skill_four": "프로파일링",
  "sidebar_skill_five": "기술 문서",
  "sidebar_projects_heading": "프로젝트",
  "sidebar_project_one": "Edge Profiler",
  "sidebar_project_one_sub": "스케줄링 + 텔레메트리",
  "sidebar_project_two": "KV Cache Compressor",
  "sidebar_project_two_sub": "지연 기반 압축",

  "intro_heading": "스펙 시트 개요",
  "intro_body": "페이지 상단 크레딧을 따라가며 각 카드를 클릭하면 프로젝트/논문 상세를 볼 수 있습니다.",
  "intro_cta_resume": "이력서 보기",
  "intro_cta_portfolio": "포트폴리오 보기",
  "intro_cta_contact": "문의하기",

  "home_featured": "추천 작업",
  "home_intro_desc": "엔지니어링 결과와 연구를 필터로 구분하고 각 상세를 확인해보세요.",
  "filter_all": "전체",
  "filter_projects": "프로젝트",
  "filter_research": "연구",

  "work_esmoe_title": "ES-MoE 추론 최적화",
  "work_esmoe_sub": "희소 전문가 루팅 런타임",
  "work_esmoe_date": "2025.05",
  "work_orion_title": "Project Orion 엣지 스택",
  "work_orion_sub": "텔레메트리 + 복구 파이프라인",
  "work_orion_date": "2025.03",
  "work_llm_title": "효율적인 LLM 오프로딩",
  "work_llm_sub": "논문 스타일의 발견",
  "work_llm_date": "2024.11",
  "work_cxl_title": "CXL 기반 티어드 메모리",
  "work_cxl_sub": "다중 티어 배치 정책",
  "work_cxl_date": "2024.08",

  "portfolio_intro_title": "포트폴리오 개요",
  "portfolio_intro_desc": "공학 빌드와 연구를 더미 텍스트로 정리했습니다.",
  "portfolio_projects_title": "엔지니어링 프로젝트",
  "portfolio_projects_desc": "각 카드가 프로젝트 상세 페이지로 연결됩니다.",
  "portfolio_research_title": "연구 & 논문",
  "portfolio_research_desc": "피어 리뷰 논문과 실험 노트를 모아두었습니다.",

  "resume_intro_title": "이력서 스냅샷",
  "resume_intro_desc": "핸즈온 경험, 논문, 수상 기록을 정리했습니다.",
  "resume_experience_title": "경력",
  "resume_exp1_role": "대학원 연구원 · ACAS Lab",
  "resume_exp1_period": "2025 - 현재",
  "resume_exp1_desc": "하이브리드 GPU/PIM 클러스터를 위한 추론 최적화와 런타임 자동화를 구축합니다.",
  "resume_exp2_role": "시스템 엔지니어 인턴 · FlexGen",
  "resume_exp2_period": "2024 여름",
  "resume_exp2_desc": "KV 캐시 스케줄링 커널과 벤치마크 자동화 코드를 구현했습니다.",
  "resume_exp3_role": "시스템 프로그래밍 TA",
  "resume_exp3_period": "2024",
  "resume_exp3_desc": "Verilog, GPU 시뮬레이터, OS 계측 실습을 40명 이상에게 강의했습니다.",
  "resume_research_title": "연구 하이라이트",
  "resume_pub1_title": "ES-MoE: 엣지 전문가 추론",
  "resume_pub1_meta": "리뷰 중 · 제1저자",
  "resume_pub2_title": "Memory-aware LLM offloading",
  "resume_pub2_meta": "MLSys 2024 · 공저자",
  "resume_pub3_title": "CXL-aware Tiering Policies",
  "resume_pub3_meta": "HPCA 2023 · 공저자",
  "resume_projects_title": "대표 빌드",
  "resume_proj1_title": "Project Orion 텔레메트리",
  "resume_proj1_desc": "내결함 실시간 동기화와 헬스 스코어 파이프라인.",
  "resume_proj2_title": "FlexBench 프로파일링",
  "resume_proj2_desc": "LLM 컴포넌트 지연/전력 측정 도구.",
  "resume_awards_title": "수상 & 인정",
  "resume_award1_title": "KAIST 대통령 장학금",
  "resume_award1_desc": "상위 1% 연구자 대상 전액 장학",
  "resume_award2_title": "우수 조교상",
  "resume_award2_desc": "System Programming · 2024 봄",

  "contact_intro_title": "문의 안내",
  "contact_intro_desc": "방문, 강연, 공동 연구 모두 환영합니다.",
  "contact_card_lab_title": "랩 방문",
  "contact_card_lab_desc": "주간 연구 데모와 실습에 참여할 수 있습니다.",
  "contact_card_talks_title": "강연",
  "contact_card_talks_desc": "온디바이스 AI와 GPU 메모리 튜닝의 강연을 제공합니다.",
  "contact_card_collab_title": "협업",
  "contact_card_collab_desc": "오프로드 툴링과 시스템 프로그래밍 협업을 찾고 있습니다.",
  "contact_form_title": "간단한 메시지",
  "contact_form_desc": "어떤 주제로 연락하실지 적어주시면 빠르게 회신합니다.",
  "contact_form_name": "이름",
  "contact_form_email": "이메일",
  "contact_form_message": "프로젝트 내용",
  "contact_form_cta": "보내기",

  "detail_label_role": "역할",
  "detail_label_timeline": "기간",
  "detail_label_stack": "기술",
  "detail_overview_heading": "개요",
  "detail_contribution_heading": "핵심 기여",
  "detail_findings_heading": "연구 결과",
  "detail_outcome_heading": "임팩트",
  "detail_btn_visit": "사이트",
  "detail_btn_deck": "자료",
  "detail_btn_paper": "논문",
  "detail_btn_slides": "슬라이드",

  "detail_esmoe_title": "ES-MoE 추론 최적화",
  "detail_esmoe_subtitle": "엣지 GPU 전문가 스케일링",
  "detail_esmoe_role": "리드 연구자",
  "detail_esmoe_timeline": "2024 - 2025",
  "detail_esmoe_stack": "PyTorch, CUDA Graphs, Triton",
  "detail_esmoe_overview": "희소 전문가 라우팅과 관측 스택으로 저지연 추론을 유지합니다.",
  "detail_esmoe_point1": "40µs 내의 전문 선택 로직.",
  "detail_esmoe_point2": "스트리밍 KV 캐시 압축으로 2배 처리량.",
  "detail_esmoe_point3": "전문가별 사용률 대시보드.",
  "detail_esmoe_outcome": "데모 로봇에서 38% 지연 감소.",

  "detail_orion_title": "Project Orion 엣지",
  "detail_orion_subtitle": "자율 드론 텔레메트리",
  "detail_orion_role": "시스템 엔지니어",
  "detail_orion_timeline": "2023 - 2024",
  "detail_orion_stack": "Rust, gRPC, Prometheus, Azure IoT",
  "detail_orion_overview": "불안정한 네트워크에서도 GPU와 미션 데이터 동기화합니다.",
  "detail_orion_point1": "15분 통신 두절 방어 버퍼링.",
  "detail_orion_point2": "GPU 열 스로틀 즉시 노출.",
  "detail_orion_point3": "미션 재생 대시보드 제공.",
  "detail_orion_outcome": "지원 이슈 45% 감소, 12개 파일럿에서 무인 운영.",

  "detail_llm_title": "효율적인 LLM 오프로딩",
  "detail_llm_subtitle": "모바일 GPU 파이프라인",
  "detail_llm_role": "제1저자",
  "detail_llm_timeline": "2024",
  "detail_llm_stack": "CUDA, PyTorch, FlexGen, TensorRT",
  "detail_llm_overview": "메모리 예산을 지키면서 긴 시퀀스를 처리하는 하이브리ッド 실행.",
  "detail_llm_point1": "프리필·디코드 겹침 모델.",
  "detail_llm_point2": "6GB VRAM 내 캐시 축출 유지.",
  "detail_llm_point3": "Jetson Orin에서 1.6배 처리량.",
  "detail_llm_outcome": "모바일 LLM 배포 가이드로 활용.",

  "detail_cxl_title": "CXL 기반 티어드 메모리",
  "detail_cxl_subtitle": "HBM + CXL 클러스터",
  "detail_cxl_role": "공저자",
  "detail_cxl_timeline": "2023",
  "detail_cxl_stack": "CXL 시뮬레이터, Python, NVProf",
  "detail_cxl_overview": "CXL 확장기를 갖춘 다중 티어 시스템의 KV 캐시 정책을 탐색합니다.",
  "detail_cxl_point1": "텐서를 CXL로 옮길지 결정하는 지연 예측.",
  "detail_cxl_point2": "큐 지연 스파이크에 반응하는 컨트롤러.",
  "detail_cxl_point3": "CXL+HBM 혼합으로 27% 비용 절감.",
  "detail_cxl_outcome": "산업 파트너 로드맵에 반영.",

  "footer_text": "(C) 2025 Your Name. All Rights Reserved."
}
`), jp: JSON.parse(`{
  "brand_name": "Your Name",
  "brand_title": "?룔궧?녴깲?틻I?붺㈅??,

  "nav_home": "?쎼꺖??,
  "nav_resume": "掠ζ???,
  "nav_portfolio": "?앫꺖?덀깢?⒲꺁??,
  "nav_contact": "?ｇ덧",

  "profile_name": "Your Name",
  "profile_title": "On-device AI / GPU ?먦꺖?곥깵?⒲궎?쇈꺖?룔깾??,
  "profile_summary": "?뤵꺖?됥궑?㎯궋?ユ??⒴뙑?뺛굦?욻L?믦Þ鼇덀걮?곩츪?뗧뵪?с깧?ャ겎?밤궞?쇈꺂?뺛걵?뗣궥?밤깇?졼굮礪뗧칹?쀣겲?쇻?,

  "sidebar_profile_heading": "?뗤볶?쀣꺆?뺛궍?쇈꺂",
  "sidebar_profile_body": "?룔궧?녴깲鼇?쮫?곥궧?덀꺖?ゃ꺖?곥깤??깉?욍궎?쀣겎筽뉔썞?ょ젘令뜰굮若잒죱??꺗?ゆ닇?쒌겓鸚됥걟?얇걲??,
  "sidebar_contact_heading": "?녈꺍?욍궚??,
  "sidebar_contact_email_label": "?▲꺖??,
  "sidebar_contact_email_value": "hello@example.com",
  "sidebar_contact_phone_label": "?삭㈀",
  "sidebar_contact_phone_value": "+82-10-0000-0000",
  "sidebar_contact_location_label": "?닸?",
  "sidebar_contact_location_value": "?썬궑??/ 鸚㎫뵲",
  "sidebar_contact_site_label": "?듐궎??,
  "sidebar_contact_site_value": "example.com",
  "sidebar_education_heading": "耶??",
  "sidebar_education_one": "KAIST 쨌 M.S. Computer Science",
  "sidebar_education_one_sub": "2023 - 2025",
  "sidebar_education_two": "KAIST 쨌 B.S. Electrical Engineering",
  "sidebar_education_two_sub": "2019 - 2023",
  "sidebar_skills_heading": "?밤궘??,
  "sidebar_skill_one": "?ゃ꺍?뉎깘?ㅳ궧AI",
  "sidebar_skill_two": "GPU?먦꺖?곥깵?⒲궎?쇈꺖?룔깾??,
  "sidebar_skill_three": "Mixture-of-Experts",
  "sidebar_skill_four": "?쀣꺆?뺛궊?ㅳ꺁?녈궛",
  "sidebar_skill_five": "?烏볝깋??깷?▲꺍??,
  "sidebar_projects_heading": "?쀣꺆?멥궒??깉",
  "sidebar_project_one": "Edge Profiler",
  "sidebar_project_one_sub": "?밤궞?멥깷?쇈꺁?녈궛?삠깇?с깳?덀꺁",
  "sidebar_project_two": "KV Cache Compressor",
  "sidebar_project_two_sub": "?с궎?녴꺍?룔꺖?㎫리",

  "intro_heading": "?밤깪?껁궚?룔꺖?덃쫩誤?,
  "intro_body": "?볝겗?싥꺖?멥걢?됧릢?ャ꺖?됥겎?쀣꺆?멥궒??깉?꾥쳳?뉎겗屋녕눗?싥꺖?멥겦燁삣땿?㎯걤?얇걲??,
  "intro_cta_resume": "掠ζ??멥굮誤뗣굥",
  "intro_cta_portfolio": "?앫꺖?덀깢?⒲꺁?ゃ굮誤뗣굥",
  "intro_cta_contact": "?ｇ덧?믧곥굥",

  "home_featured": "力①쎅??퐳??,
  "home_intro_desc": "?ⓦ꺍?멥깑?㏂꺁?녈궛?먩옖?①젘令뜰굮?뺛궍?ャ궭?쀣겍?곩릢屋녕눗?싥꺖?멥굮?붻├?뤵걽?뺛걚??,
  "filter_all": "?ⓦ겍",
  "filter_projects": "?쀣꺆?멥궒??깉",
  "filter_research": "?붺㈅",

  "work_esmoe_title": "ES-MoE ?②쳳??⒴뙑",
  "work_esmoe_sub": "?밤깙?쇈궧?ⓦ궘?밤깙?쇈깉?ャ꺖?녴궍?녈궛",
  "work_esmoe_date": "2025.05",
  "work_orion_title": "Project Orion ?ⓦ긿?멥궧?욍긿??,
  "work_orion_sub": "?녴꺃?▲깉?わ펻孃⒵뿧?묆궎?쀣꺀?ㅳ꺍",
  "work_orion_date": "2025.03",
  "work_llm_title": "?밭럤?꾠겒LLM?ゃ깢??꺖?뉎궍?녈궛",
  "work_llm_sub": "?멥깵?쇈깏?ャ궧?욍궎?ャ겗?븃쫳",
  "work_llm_date": "2024.11",
  "work_cxl_title": "CXL野얍퓶??깇?ｃ궋?됥깳?㏂꺁",
  "work_cxl_sub": "?욁꺂?곥깇?ｃ궋?띸쉰?앫꺁?룔꺖",
  "work_cxl_date": "2024.08",

  "portfolio_intro_title": "?앫꺖?덀깢?⒲꺁?ゃ겗礖귟쫨",
  "portfolio_intro_desc": "?ⓦ꺍?멥깑?㏂꺁?녈궛?①젘令뜻닇?쒌굮??잆꺖?녴궘?밤깉?㎯겲?ⓦ굙?╉걚?얇걲??,
  "portfolio_projects_title": "?ⓦ꺍?멥깑?㏂꺁?녈궛?쀣꺆?멥궒??깉",
  "portfolio_projects_desc": "?꾠궭?ㅳ꺂?뚣깤??궦?㎯궚?덀겗屋녕눗?싥꺖?멥겓?ゃ꺍??걮?얇걲??,
  "portfolio_research_title": "?붺㈅?②쳳??,
  "portfolio_research_desc": "?삭き餓섅걤獄뽪뻼?ⓨ츪蟯볝깕?쇈깉?믣룑?녴걮?얇걮?잆?,

  "resume_intro_title": "掠ζ??멥겗?밤깏?껁깤?룔깾?껁깉",
  "resume_intro_desc": "若잌떃永뚪쮶?곭젘令뜰곩룛蘊욁굮?얇겏?곥걼?싥꺖?멥겎?쇻?,
  "resume_experience_title": "永뚪쮶",
  "resume_exp1_role": "鸚㎩??®젘令뜹뱻 쨌 ACAS Lab",
  "resume_exp1_period": "2025 - ?얍쑉",
  "resume_exp1_desc": "?뤵궎?뽧꺁?껁깋GPU/PIM??꺀?밤궭?㎯겗?②쳳??⒴뙑?ⓦ꺀?녈궭?ㅳ깲?ゅ땿?뽧굮?끻퐪??,
  "resume_exp2_role": "?룔궧?녴깲?ⓦ꺍?멥깑?㏂궎?녈궭?쇈꺍 쨌 FlexGen",
  "resume_exp2_period": "2024亮닷쨵",
  "resume_exp2_desc": "KV??깵?껁궥?γ궧?긱궦?γ꺖?ゃ꺍?겹궖?쇈깓?ャ겏?쇻꺍?곥깯?쇈궚?ゅ땿?뽧굮若잒즳??,
  "resume_exp3_role": "?룔궧?녴깲?쀣꺆?겹꺀?잆꺍?캴A",
  "resume_exp3_period": "2024",
  "resume_exp3_desc": "40?띴빳訝듽겓Verilog?갍PU?룔깱?γ꺃?쇈궭?쇈갣S鼇덃릍??폇玲믡굮?뉐컣??,
  "resume_research_title": "?붺㈅?뤵궎?⒲궎??,
  "resume_pub1_title": "ES-MoE: ?ⓦ긿?멨컗??②쳳",
  "resume_pub1_meta": "?삭き訝?쨌 寧т??쀨?,
  "resume_pub2_title": "Memory-aware LLM offloading",
  "resume_pub2_meta": "MLSys 2024 쨌 ?김몭",
  "resume_pub3_title": "CXL-aware Tiering Policies",
  "resume_pub3_meta": "HPCA 2023 쨌 ?김몭",
  "resume_projects_title": "餓ｈ〃?쀣꺆?멥궒??깉",
  "resume_proj1_title": "Project Orion ?녴꺃?▲깉??,
  "resume_proj1_desc": "?먬슌若녔㎯겗?귙굥?뚧쐿?ⓦ꺁?㏂꺂?욍궎?졾겈佯룔궧?녈궋?ゃ꺍?겹?,
  "resume_proj2_title": "FlexBench ?쀣꺆?뺛궊?ㅳ꺁?녈궛",
  "resume_proj2_desc": "LLM礪뗦닇誤곭킔??꺃?ㅳ깇?녈궥/?삣뒟歷у츣?꾠꺖?ャ?,
  "resume_awards_title": "?쀨퀪 & 沃띸윥",
  "resume_award1_title": "KAIST 鸚㎫뎠?섇ⅷ耶?뇫",
  "resume_award1_desc": "訝듾퐤1%?붺㈅?끹겦??뀲窈띶ⅷ耶?뇫",
  "resume_award2_title": "?ょ?TA蘊?,
  "resume_award2_desc": "System Programming 쨌 2024??,

  "contact_intro_title": "?듿븦?꾢릦?뤵걵",
  "contact_intro_desc": "鼇ゅ븦?곮쵙轢붵곩뀻?뚨젘令뜰걲?밤겍閭볢퓥?㎯걲??,
  "contact_card_lab_title": "?⒲깭鼇ゅ븦",
  "contact_card_lab_desc": "?길А??젘令뜰깈?㏂굜若잏퓪?ュ뢿?졼겎?띲겲?쇻?,
  "contact_card_talks_title": "玉쎿폇",
  "contact_card_talks_desc": "?ゃ꺍?뉎깘?ㅳ궧AI?껯PU?▲깴?ゃ긽?γ꺖?뗣꺍?겹겗屋긱굮?쀣겲?쇻?,
  "contact_card_collab_title": "?붹?",
  "contact_card_collab_desc": "?ゃ깢??꺖?뉎궍?녈궛?꾠꺖?ャ굜?룔궧?녴깲礪뗧칹?㎩뜑璵?굮閭볢퓥?쀣겲?쇻?,
  "contact_form_title": "??궎?껁궚?▲긿?삠꺖??,
  "contact_form_desc": "屋긱걮?잆걚?덀깞?껁궚?믦쮼?γ걮?╉걦?졼걬?꾠귙걲?먦겓瓦붶에?쀣겲?쇻?,
  "contact_form_name": "?듿릫??,
  "contact_form_email": "?▲꺖??,
  "contact_form_message": "?붺쎑獄뉐냵若?,
  "contact_form_cta": "?곦에",

  "detail_label_role": "壤밧돯",
  "detail_label_timeline": "?잓뼋",
  "detail_label_stack": "?烏?,
  "detail_overview_heading": "礖귟쫨",
  "detail_contribution_heading": "訝삠겒縕®뙫",
  "detail_findings_heading": "?붺㈅永먩옖",
  "detail_outcome_heading": "?ㅳ꺍?묆궚??,
  "detail_btn_visit": "?듐궎??,
  "detail_btn_deck": "蘊뉑뼑",
  "detail_btn_paper": "獄뽪뻼",
  "detail_btn_slides": "?밤꺀?ㅳ깋",

  "detail_esmoe_title": "ES-MoE ?②쳳??⒴뙑",
  "detail_esmoe_subtitle": "?ⓦ긿?퇖PU?묆걨弱귡??밤궞?쇈꺁?녈궛",
  "detail_esmoe_role": "?ゃ꺖?됬젘令띈?,
  "detail_esmoe_timeline": "2024 - 2025",
  "detail_esmoe_stack": "PyTorch, CUDA Graphs, Triton",
  "detail_esmoe_overview": "?밤깙?쇈궧弱귡??ャ꺖?녴궍?녈궛?ⓦ깴?뗣궭?ゃ꺍?겹궧?욍긿??겎弱뤷엹GPU?㎯굚鵝롢꺃?ㅳ깇?녈궥?믣츪?얇?,
  "detail_esmoe_point1": "?с궎?녴꺍?룔굮?뤺춼?쀣걼弱귡??멩뒢??0쨉s?㎩츪烏뚣?,
  "detail_esmoe_point2": "?밤깉?ゃ꺖?잆꺍?캩V??깵?껁궥?ε쑇潁?겎2?띲겗?밤꺂?쇈깤?껁깉?붹닇??,
  "detail_esmoe_point3": "??껁궥?γ깭?쇈깋?㎩컗??ε닶?①럤?믣룾誤뽩뙑??,
  "detail_esmoe_outcome": "?뉎깴??깭?껁깉??8%??꺃?ㅳ깇?녈궥?딀툤??,

  "detail_orion_title": "Project Orion ?ⓦ긿??,
  "detail_orion_subtitle": "?ゅ풃?됥꺆?쇈꺍??깇?с깳?덀꺁",
  "detail_orion_role": "?룔궧?녴깲?ⓦ꺍?멥깑??,
  "detail_orion_timeline": "2023 - 2024",
  "detail_orion_stack": "Rust, gRPC, Prometheus, Azure IoT",
  "detail_orion_overview": "訝띶츎若싥겒?띲긿?덀꺈?쇈궚?㎯굚GPU?▲깉?ゃ궚?밤겏?잆긿?룔깾?녈깈?쇈궭?믣릪?잆?,
  "detail_orion_point1": "15?녴겗?η텥?뉑뼪?믦먦걟?뗣깘?껁깢?▲?,
  "detail_orion_point2": "GPU?긱궧??긿?덀꺂?믣뜵?귟〃鹽뷩?,
  "detail_orion_point3": "?잆긿?룔깾?녑냽?잆??껁궥?γ깭?쇈깋?먧풘??,
  "detail_orion_outcome": "?듐깮?쇈깉餓뜻빊45%歷쎼?2餓뜰겗?묆궎??긿?덀겎?や말?뗧뵪??,

  "detail_llm_title": "?밭럤?꾠겒LLM?ゃ깢??꺖?뉎궍?녈궛",
  "detail_llm_subtitle": "?㏂깘?ㅳ꺂GPU?묆궎?쀣꺀?ㅳ꺍",
  "detail_llm_role": "寧т??쀨?,
  "detail_llm_timeline": "2024",
  "detail_llm_stack": "CUDA, PyTorch, FlexGen, TensorRT",
  "detail_llm_overview": "?▲깴?や틛嶸쀣굮若덀굤?ゃ걣?됮빓?꾠궥?쇈궞?녈궧?믥땟?곥걲?뗣깗?ㅳ깣?ゃ긿?됧츪烏뚣굮若싩쑴??,
  "detail_llm_point1": "?쀣꺁?뺛궍?ャ꺕?뉎궠?쇈깋?믧뇥??굥?㏂깈?ャ굮弱롥눣??,
  "detail_llm_point2": "6GB VRAM?끹겎暎얍벧?믥땟?곥걲?뗣궘?ｃ긿?룔깷?믣눣??,
  "detail_llm_point3": "Jetson Orin??.6?띲궧?ャ꺖?쀣긿?덀?,
  "detail_llm_outcome": "?㏂깘?ㅳ꺂LLM掠뺡뼀?с궎?됥겏?쀣겍域사뵪??,

  "detail_cxl_title": "CXL野얍퓶?녴궍?㏂꺖?됥깳?㏂꺁",
  "detail_cxl_subtitle": "HBM + CXL??꺀?밤궭",
  "detail_cxl_role": "?김몭??,
  "detail_cxl_timeline": "2023",
  "detail_cxl_stack": "CXL?룔깱?γ꺃?쇈궭, Python, NVProf",
  "detail_cxl_overview": "CXL?▼섧?믣굺?덀걼鸚싨??롢궥?밤깇?졼겎KV??깵?껁궥?η㎉?뺛깮?ゃ궥?쇈굮?㏂굥??,
  "detail_cxl_point1": "CXL?쀣꺖?ャ겦??빪?곫셽??걛兩뜸틛歷у솳??,
  "detail_cxl_point2": "??깷?쇤걛兩뜰겓恙쒐춸?쇻굥?녈꺍?덀꺆?쇈꺀??,
  "detail_cxl_point3": "CXL+HBM曆룟릦??7%?녈궧?덂뎷歷쎼?,
  "detail_cxl_outcome": "?ｆ??묆꺖?덀깏?쇈겗??꺖?됥깯?껁깤?ヨ깻???,

  "footer_text": "(C) 2025 Your Name. All Rights Reserved."
}
`) };
